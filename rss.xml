<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/">
    <channel>
        <title>Frank Cozzolino - Blog &amp; Insights</title>
        <link>https://frankcozzolino.github.io/</link>
        <description>Thoughts, ideas, and professional insights on technology, project management, and professional development</description>
        <language>en-us</language>
        <lastBuildDate>Fri, 18 Jul 2025 08:20:43 GMT</lastBuildDate>
        <ttl>60</ttl>
        <image>
            <url>https://frankcozzolino.github.io/images/signature.png</url>
            <title>Frank Cozzolino</title>
            <link>https://frankcozzolino.github.io/</link>
        </image>
        
        <item>
            <title>“AI isn’t delivering value” and “Why Firing People for AI Agents is a Costly Mistake” — 40% of…</title>
            <link>https://frankcozzolino.github.io/blog.html?article=ai-isnt-delivering-value-and-why-firing-people-for</link>
            <guid>https://frankcozzolino.github.io/blog.html?article=ai-isnt-delivering-value-and-why-firing-people-for</guid>
            <pubDate>Thu, 17 Jul 2025 08:20:20 GMT</pubDate>
            <dc:creator>Francesco C.</dc:creator>
            <category>budget</category>
            <category>product-management</category>
            <category>business-strategy</category>
            <category>corporate-culture</category>
            <category>ai</category>
            <description>“AI isn’t delivering value” and “Why Firing People for AI Agents is a Costly Mistake” — 40% of Agentic AI projects will fail.when strategy, measurement, and execution are weak and over 40% of Agentic...</description>
            <enclosure url="https://cdn-images-1.medium.com/max/1024/1*-XloYdAw_hSW_izDAL06_Q.png" type="image/jpeg" length="0"/>
            <content:encoded><![CDATA[<h3>“AI isn’t delivering value” and “Why Firing People for AI Agents is a Costly Mistake” — 40% of Agentic AI projects will fail.</h3><blockquote>when strategy, measurement, and execution are weak and over 40% of Agentic AI projects will fail by the end of 2027 due to cost hikes, murky ROI, and integration issues.</blockquote><blockquote>68% of companies are spending $50M to $250M annually on GenAI — only 31% expect to measure ROI within six months</blockquote><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*-XloYdAw_hSW_izDAL06_Q.png" /></figure><p><strong>Introduction</strong></p><p>Enterprises worldwide are embracing generative AI (GenAI) with unmatched enthusiasm. Yet behind the optimism lies a cautionary tale: <strong>rushing into AI adoption without strategic planning, financial oversight, and a clear purpose can lead to budget overruns, failed projects, and a hollow return on investment (ROI).</strong> Perhaps most dangerously, some firms are laying off staff prematurely, betting on AI agents to replace human capital. But as the evidence shows, <strong>this short-sighted strategy often leads to higher costs, compliance risks, and operational inefficiencies.</strong></p><p><strong>1. Ballooning Budgets and Unseen Costs</strong></p><p>Gartner forecasts GenAI-related spending to top <strong>$644 billion in 2025</strong>, with many enterprises surprised by costs not accounted for upfront. As seen in Thermo Fisher Scientific’s chatbot pilot, consumption-based pricing quickly spiraled out of control. What began as a promising automation initiative nearly collapsed due to unpredictable data usage fees and model hallucinations that posed compliance issues (<a href="https://www.computerworld.com/article/4021954/rushing-into-genai-prepare-for-budget-blowouts-and-broken-promises.html">Computerworld</a>).</p><p>Capgemini CEO Aiman Ezzat highlighted another failure: an internal chatbot was projected to cost <strong>$25 million annually</strong> in data processing — forcing its termination before launch. The lesson: GenAI tools often <strong>require more compute, integration, and oversight</strong> than anticipated, and costs compound rapidly with scale.</p><p>According to Gartner, custom GenAI models can cost <strong>$5–20 million to build</strong>, plus <strong>$8,000–21,000 per user per year</strong>, with API usage adding hundreds of thousands more. These expenses often surprise companies who budget only for initial implementation.</p><p><strong>2. ROI Remains Elusive</strong></p><p>Despite massive investments — <strong>68% of companies are spending $50M to $250M annually</strong> on GenAI — only <strong>31% expect to measure ROI within six months</strong> (<a href="https://www.cio.com/article/3778320/enterprises-willing-to-spend-up-to-250-million-on-gen-ai-but-roi-remains-elusive.html">CIO.com</a>). Organizations fail to align AI projects with core KPIs, and many ignore foundational needs like data governance, model explainability, and human oversight.</p><p>Even in analytics, where AI and automation should shine, companies struggle to quantify value. A TechRadar report found success only when IT leaders define metrics upfront, invest in training, and connect automation outcomes with business goals.</p><p>A McKinsey/CIO study confirms that just <strong>31% anticipate measurable value shortly</strong>, citing data, governance, and alignment as consistent lags. The lesson is clear: without discipline and alignment, even generous GenAI budgets fail to deliver.</p><p><strong>3. Project Failures and the AI Hype Hangover</strong></p><p>Gartner analysts say GenAI is moving past its “peak hype” into the <strong>“trough of disillusionment.”</strong> Many deployments in 2024 were scrapped due to unclear value or misaligned expectations (<a href="https://www.itpro.com/business/business-strategy/generative-ai-enthusiasm-continues-to-beat-out-business-uncertainty">ITPro</a>). Nearly <strong>42% of AI initiatives</strong> fail before reaching production.</p><p>Reasons include:</p><ul><li>Poor integration with legacy systems</li><li>Inaccurate or low-quality data</li><li>Ethical/legal blind spots</li><li>Lack of cross-functional leadership</li></ul><p>These pitfalls are exacerbated when firms remove experienced staff who would otherwise provide the institutional knowledge and governance required for success.</p><p>The Economist reports that abandonment of AI pilots leapt from 17% to <strong>42%</strong> in one year, with some companies rehiring staff to fix flawed systems. Anthropic’s vending machine AI failed in live trials — mispricing goods and generating nonsense — proving that human-in-the-loop oversight is not optional.</p><p><strong>4. The Human Cost: Layoffs and False Economies</strong></p><p>Many companies now equate productivity with profitability and mistakenly see GenAI as a labor cost-cutting tool. But firing employees to replace them with AI agents creates <strong>false economies.</strong></p><p>AI agents still require:</p><ul><li>Manual validation and oversight</li><li>Regular prompt engineering and tuning</li><li>Ongoing retraining on updated datasets</li></ul><p>Scale AI laid off 14% of its workforce after its GenAI pods grew too expensive and underperformed. Klarna replaced 700 service jobs with AI but quickly reversed course when quality and satisfaction dropped.</p><p>As Capgemini’s CEO warned, <strong>productivity doesn’t equal savings</strong>, especially in lower-wage roles. And as RHR International’s CIO noted, successful projects budget for human governance and experimentation — factors impossible to replace entirely with AI.</p><p>A Stanford study found that hybrid human-AI teams are <strong>14% more productive</strong> and deliver higher satisfaction than either alone. AI deployment without integrated human roles leads to chaos, not efficiency.</p><p><strong>Conclusion: Invest in AI <em>with</em> People, Not <em>instead</em> of Them</strong></p><p>Generative AI holds enormous potential. But chasing savings by cutting headcount and offloading critical roles to AI agents is a misstep that will likely cost companies more in the long run — through failed projects, regulatory risks, and lost trust.</p><p><strong>AI should augment, not replace, your workforce.</strong></p><p>The future belongs to those who pair machine intelligence with human judgment — strategically, ethically, and with financial clarity. Companies that rush blindly forward will pay twice: once in money, and again in lost opportunity.</p><h3>Thank you for being a part of the community</h3><p><em>Before you go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writer ️👏<strong>️️</strong></li><li>Follow us: <a href="https://x.com/inPlainEngHQ"><strong>X</strong></a> | <a href="https://www.linkedin.com/company/inplainenglish/"><strong>LinkedIn</strong></a> | <a href="https://www.youtube.com/@InPlainEnglish"><strong>YouTube</strong></a> | <a href="https://newsletter.plainenglish.io/"><strong>Newsletter</strong></a> | <a href="https://open.spotify.com/show/7qxylRWKhvZwMz2WuEoua0"><strong>Podcast</strong></a> | <a href="https://twitch.tv/inplainenglish"><strong>Twitch</strong></a></li><li><a href="https://differ.blog/"><strong>Start your own free AI-powered blog on Differ</strong></a> 🚀</li><li><a href="https://discord.gg/in-plain-english-709094664682340443"><strong>Join our content creators community on Discord</strong></a> 🧑🏻‍💻</li><li>For more content, visit <a href="https://plainenglish.io/"><strong>plainenglish.io</strong></a> + <a href="https://stackademic.com/"><strong>stackademic.com</strong></a></li></ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=03b77684a261" width="1" height="1" alt=""><hr><p><a href="https://blog.venturemagazine.net/ai-isnt-delivering-value-and-why-firing-people-for-ai-agents-is-a-costly-mistake-40-of-03b77684a261">“AI isn’t delivering value” and “Why Firing People for AI Agents is a Costly Mistake” — 40% of…</a> was originally published in <a href="https://blog.venturemagazine.net">Venture</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        
        <item>
            <title>I am Sorry, but We will never talk to ET</title>
            <link>https://frankcozzolino.github.io/blog.html?article=i-am-sorry-but-we-will-never-talk-to-et</link>
            <guid>https://frankcozzolino.github.io/blog.html?article=i-am-sorry-but-we-will-never-talk-to-et</guid>
            <pubDate>Thu, 26 Jun 2025 15:35:01 GMT</pubDate>
            <dc:creator>Francesco C.</dc:creator>
            <category>astronomy</category>
            <category>astrophysics</category>
            <category>ufology</category>
            <category>ufo</category>
            <category>ufos-and-aliens</category>
            <description>The life in the universe might not be rare, but definitely rarer than what we expected.The Drake equation has a lot of guessing, but even in our Solar system and nearby stars we tend to be alone....</description>
            <enclosure url="https://cdn-images-1.medium.com/max/1024/1*59rASJy1onpWv2dsBBhPrA.png" type="image/jpeg" length="0"/>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*59rASJy1onpWv2dsBBhPrA.png" /></figure><p>The life in the universe might not be rare, but definitely rarer than what we expected.</p><p>The Drake equation has a lot of guessing, but even in our Solar system and nearby stars we tend to be alone. Even microbes which should be everywhere seems to not be present anywhere in our Solar System (so far), which should be a good indicator that even the parameters below might be not very conservatives.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/928/1*ZBKoQsog-Lmakh3Stc0mWQ.png" /></figure><p>50000 species in the entire universe, since the beginning. Seems extremely small amount, and it is frightening to think about the implication of that number.</p><p>Nonetheless, we have another obstacle, that’s the great filter, and our technological revolution is extremely young. Moreover, we arrived very late to the party. Most of species could be already be extincted billions of years ago.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/791/1*hzTXCYTx9gwrDiymxCSl4Q.png" /><figcaption>We ourselves appear at <strong>13.8 Gyr → in the “Late” epoch</strong>, near the trailing edge of cosmic habitability.</figcaption></figure><p>So, accounting for this the probability that we detect any other specie is basically 0.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/810/1*rzw6RsPsGo_s4nf38zXTAQ.png" /><figcaption>table showing, for each scenario, the expected number of detectable civilizations within our 100 ly listening volume and the corresponding probability (assuming a Poisson process, so P(≥1)≈NdetectP(\ge1)\approx N_{\rm detect}P(≥1)≈Ndetect​ for Ndetect≪1N_{\rm detect}\ll1Ndetect​≪1):</figcaption></figure><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=358236cdb664" width="1" height="1" alt="">]]></content:encoded>
        </item>
        
        <item>
            <title>Little-known Google Auth Feature that allows you to exchange PingFederate Token with Google Access…</title>
            <link>https://frankcozzolino.github.io/blog.html?article=littleknown-google-auth-feature-that-allows-you-to</link>
            <guid>https://frankcozzolino.github.io/blog.html?article=littleknown-google-auth-feature-that-allows-you-to</guid>
            <pubDate>Thu, 26 Jun 2025 08:23:16 GMT</pubDate>
            <dc:creator>Francesco C.</dc:creator>
            <category>google</category>
            <category>token</category>
            <category>authorization</category>
            <category>pingfederate</category>
            <category>google-cloud-platform</category>
            <description>Little-known Google Auth Feature that allows you to exchange PingFederate Token with Google Access Token🎫 The Golden Ticket (Authorization Code)As a golden ticket in the OAuth 2.0 flow, the...</description>
            <enclosure url="https://cdn-images-1.medium.com/max/1024/0*Ii2CrjYQfJw0L0Ud" type="image/jpeg" length="0"/>
            <content:encoded><![CDATA[<h3>Little-known Google Auth Feature that allows you to exchange PingFederate Token with Google Access Token</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*Ii2CrjYQfJw0L0Ud" /></figure><h3>🎫 The Golden Ticket (Authorization Code)</h3><p>As a golden ticket in the OAuth 2.0 flow, the authorization code is a precious, short-lived credential representing proof of user consent. Issued by Google’s authorization server once a user authenticates and grants your application the requested scopes, this single-use code is an 80 — 120-character, Base64-encoded string (e.g., “4/0AVG7fiQ7G…”) that is bound to your app’s client_id and the exact redirect_uri used in the initial request. Though it travels through potentially insecure channels like browser URL parameters, it remains useless to any attacker because it can only be redeemed at Google’s token endpoint in exchange for access and refresh tokens when presented alongside your client_secret. With a strict expiration window of about ten minutes and built-in cryptographic safeguards, the authorization code can safely bridge user consent to long-term API credentials without exposing your app’s secrets.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*2EFok-VbgwEMEOlL" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*pv0Pkf4KyTmcBmC5" /></figure><h3>Example</h3><pre>const tokenResponse = await fetch(&#39;https://oauth2.googleapis.com/token&#39;, {<br>    method: &#39;POST&#39;,<br>    headers: { &#39;Content-Type&#39;: &#39;application/x-www-form-urlencoded&#39; },<br>    body: new URLSearchParams({<br>      code,<br>      client_id: process.env.GOOGLE_CLIENT_ID || &#39;&#39;,<br>      client_secret: process.env.GOOGLE_CLIENT_SECRET || &#39;&#39;,<br>      redirect_uri: process.env.GOOGLE_REDIRECT_URI || &#39;&#39;,<br>      grant_type: &#39;authorization_code&#39;,<br>    }),<br>  });</pre><h3>References</h3><p><a href="https://developers.google.com/identity/protocols/oauth2">https://developers.google.com/identity/protocols/oauth2</a></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=679573ade04f" width="1" height="1" alt="">]]></content:encoded>
        </item>
        
        <item>
            <title>The WWW is almost dead, what next?</title>
            <link>https://frankcozzolino.github.io/blog.html?article=the-www-is-almost-dead-what-next</link>
            <guid>https://frankcozzolino.github.io/blog.html?article=the-www-is-almost-dead-what-next</guid>
            <pubDate>Wed, 25 Jun 2025 09:19:23 GMT</pubDate>
            <dc:creator>Francesco C.</dc:creator>
            <category>democracy</category>
            <category>ai</category>
            <category>humanity</category>
            <category>social-media</category>
            <category>internet</category>
            <description>From the gritty garages of Silicon Valley to the neon lit high rises of Manhattan, the World Wide Web burst onto the scene in 1991 as Tim Berners Lee’s brainchild at CERN. What started as a simple...</description>
            <enclosure url="https://cdn-images-1.medium.com/max/1024/1*fkaVio8nZNIIybBB6Xzmeg.png" type="image/jpeg" length="0"/>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*fkaVio8nZNIIybBB6Xzmeg.png" /></figure><p>From the gritty garages of Silicon Valley to the neon lit high rises of Manhattan, the World Wide Web burst onto the scene in 1991 as Tim Berners Lee’s brainchild at CERN. What started as a simple network of hyperlinked documents quickly morphed into a digital coliseum, with browsers duking it out on desktop stages and dot com fortunes rising and crashing faster than a subway express. By the turn of the millennium, the Web had rewired everything newsstands, corner bodegas, Wall Street tickers turning every New Yorker into a pixel in the global grid.</p><p>In the 1990s, the Internet kicked off as a noisy neon bazaar: dial‑up modems chirped in suburban bedrooms while Netscape Navigator ruled the streets, and Geocities homepages bloomed like wild graffiti. Bulletin boards and IRC channels became the cool underground clubs where chat room denizens swapped ASCII art and MP3s on Napster lit the fire for digital file sharing. By the turn of the millennium, the dot‑com boom turned startups into overnight Wall Street darlings pets.com and pets spelled out the risks of unbridled hype when the bubble burst in 2000.<br>The early 2000s reloaded the Web into Version 2.0: blogs sprouted like newsstands on every corner, MySpace’s rocker profiles and Friendster’s exclusive clubs set the template, and e‑commerce giants like Amazon and eBay turned one‑click buying into a citywide habit. Streaming video and podcasts began rumbling beneath the surface, while broadband quietly replaced dial‑up, ushering in faster scrolls and richer media. This era proved that between the dial‑up thunks and the post‑bubble revelations, the Internet wasn’t just a passing fad but a gritty, evolving metropolis one built on community, commerce, and the code to keep hustling.</p><p>Enter the AI era, the World Wide Web, once a sprawling agora of shared ideas and unbridled curiosity, lies comatose. In its place stands an ironclad ecosystem of “knowledge” meticulously distilled into soulless shards by faceless corporations and opaque government bureaus. Welcome to our new digital age: a sterile, privatized vault where every byte of information is bartered, fenced off, and rationed to suit the whims of remote data barons.</p><p>Digital isolation has become the default. No longer do communities gather in bustling chatrooms or exchange ideas freely across blogs. Instead, individuals retreat into algorithmically sanctioned bubbles small, well lit cages that hum with the comforting glow of curated content. Don’t bother wandering beyond the paywalls and firewalls; you’ll find nothing but echoes of your own preferences, an intoxicating loop designed to keep you clicking and consuming until the model dictates otherwise.<br>Knowledge fenced gardens are flourishing. Major tech conglomerates now host “premium” archives of the human record, available only via subscription tiers that rival luxury car leases. Want to read the complete works of Shakespeare? That’ll be €19.99 a month, please. Need the latest climate data? First you must verify your identity and prove you’ve purchased the “Enterprise Insights” package. These walled off libraries masquerade as convenience, but the truth is blatant: profit has trumped public good, and we’re left paying tribute to invisible gatekeepers.<br>Privatization of knowledge isn’t subtle. Governments, under the guise of “national security,” have signed lucrative licensing deals with private model providers, effectively offloading public archives into corporate vaults. What was once funded by tax dollars is now repackaged as exclusive “insights” for a privileged few. Even academic research once a bastion of open peer review has been siphoned into restricted APIs that throttle access unless you hold the right credentials or credit card.</p><p>The social fabric has frayed. We are less social, more alone in our digital cocoons. Physical proximity no longer guarantees authenticity; nor does online proximity. Your next door neighbor might be a manufactured persona in a mass produced chat interface. Friends you thought you knew on Discord could just as easily be bots, churning out canned sympathies in response to your darkest confessions. Emotional labor is outsourced to simulacra, making genuine human connection a relic of a bygone era.<br>Once the go to hunting grounds for late night confidences and pixel perfect romances chatrooms, forums and dating apps now reek of synthetic sincerity. You pour your heart out over text or even video, only to realize the “person” on the other end might be nothing more than a neural puppet. Those laugh track jokes, the perfectly timed empathies, the coy good morning selfies they’re all expertly generated by black box models designed to keep you hooked. You can’t swipe right on authenticity when every profile could be a cleverly animated façade, every “I miss you” a line of code, and every “let’s video chat” a deepfake waiting to expose your most private moments to corporate auditors. And here’s the clincher: you never know whether you’re talking to a human or a neural network. Every article, every comment, every “live” video stream is suspect. Content could be fabricated from scratch by generative models that have ingested our collective culture and spat it back out, polished to a deceptive shine. Skepticism is the only currency left yet skepticism itself has been commodified into “fact checking” services that charge per claim.</p><p>So, farewell to the democratized dream of the early internet. The web is dead, and all hail the new overlords of data.</p><p>To be continued …</p><h3>Thank you for being a part of the community</h3><p><em>Before you go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writer ️👏<strong>️️</strong></li><li>Follow us: <a href="https://x.com/inPlainEngHQ"><strong>X</strong></a> | <a href="https://www.linkedin.com/company/inplainenglish/"><strong>LinkedIn</strong></a> | <a href="https://www.youtube.com/@InPlainEnglish"><strong>YouTube</strong></a> | <a href="https://newsletter.plainenglish.io/"><strong>Newsletter</strong></a> | <a href="https://open.spotify.com/show/7qxylRWKhvZwMz2WuEoua0"><strong>Podcast</strong></a> | <a href="https://twitch.tv/inplainenglish"><strong>Twitch</strong></a></li><li><a href="https://differ.blog/"><strong>Start your own free AI-powered blog on Differ</strong></a> 🚀</li><li><a href="https://discord.gg/in-plain-english-709094664682340443"><strong>Join our content creators community on Discord</strong></a> 🧑🏻‍💻</li><li>For more content, visit <a href="https://plainenglish.io/"><strong>plainenglish.io</strong></a> + <a href="https://stackademic.com/"><strong>stackademic.com</strong></a></li></ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=a1199883f200" width="1" height="1" alt=""><hr><p><a href="https://blog.stackademic.com/the-www-is-almost-dead-what-next-a1199883f200">The WWW is almost dead, what next?</a> was originally published in <a href="https://blog.stackademic.com">Stackademic</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        
        <item>
            <title>Vibe Coding 2/5 —From Vibe coding to UML Coding.</title>
            <link>https://frankcozzolino.github.io/blog.html?article=vibe-coding-25-from-vibe-coding-to-uml-coding</link>
            <guid>https://frankcozzolino.github.io/blog.html?article=vibe-coding-25-from-vibe-coding-to-uml-coding</guid>
            <pubDate>Mon, 23 Jun 2025 07:50:06 GMT</pubDate>
            <dc:creator>Francesco C.</dc:creator>
            <category>cursor-ai</category>
            <category>vibe-coding</category>
            <category>cursor</category>
            <category>uml-diagrams</category>
            <category>ai-coding</category>
            <description>“Vibe coding is fun, but it lacks professionalism and causes many people to burn out due to bad results. Luckily, CS classes have taught UML design for pretty much forever. Almost no vibe coders...</description>
            <enclosure url="https://cdn-images-1.medium.com/max/1024/1*pcUG-skiFHVpVHCPO1lbRg.png" type="image/jpeg" length="0"/>
            <content:encoded><![CDATA[<p>“Vibe coding is fun, but it lacks professionalism and causes many people to burn out due to bad results. Luckily, CS classes have taught UML design for pretty much forever. Almost no vibe coders today use UML; most merely “type with the model.” No wonder they feel the drain.”</p><p>Read “Vibe Coding 2/5 — From Vibe coding to UML Coding “ by Francesco C. on Medium: <a href="https://medium.com/@francesco.cozzolino/vibe-coding-2-5-from-vibe-coding-to-uml-coding-711e5510de29">https://medium.com/@francesco.cozzolino/vibe-coding-2-5-from-vibe-coding-to-uml-coding-711e5510de29</a></p><h3>The book</h3><p>I strongly advice everyone to purchase this book and absorb everything said. This book pretty much changed my life and made me better, showed me the way, this goes beyond programming, this methodology you can apply to any Big Problem you will face in the life.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*pcUG-skiFHVpVHCPO1lbRg.png" /></figure><h3>The Shift from Coders to Architects</h3><p>Think of it as an evolution, not a replacement. The arrival of AI in software development isn’t about eliminating our roles — it’s about transforming them. Instead of spending 99% of our time typing lines of code, we’ll shift our focus toward:</p><ul><li><strong>Architectural design (UML)</strong></li><li><strong>Security protocols</strong></li><li><strong>AI strategy and governance</strong></li></ul><p>In effect, we become <strong>project architects by default</strong>. Our deep knowledge of design patterns, threat modeling, and system diagrams becomes the currency of innovation, while AI handles the boilerplate.</p><h3>The Big-Picture Imperative</h3><p>It’s like when hunter-gatherers first turned to agriculture. They no longer spent every waking moment foraging; they could build sturdier homes, sharpen better tools, and cultivate culture. If our goal is to conquer the galaxy, we can’t do it one line of code at a time. We need to understand the architecture of the universe itself.</p><p>AI liberates us from the minutiae: the endless debugging, the repetitive refactoring, the routine unit tests. Instead, we ask bigger questions:</p><ul><li>How do we secure quantum-resistant communication?</li><li>What standards govern AI ethics across interplanetary networks?</li><li>How can we design self-healing architectures that adapt in real time?</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*nGx1xUK18QbaGlw0-k_Jrw.png" /></figure><h3>What is UML?</h3><p>UML Unified Modeling Language (UML) is a powerful, standardized modeling language that emerged from the field of software engineering, primarily designed to specify, visualize, construct, and document software systems. Developed in the 1990s by industry leaders Grady Booch, James Rumbaugh, and Ivar Jacobson, UML became a critical tool for software developers, providing clarity and consistency in system design and facilitating effective communication among development teams. Its broad acceptance is due largely to its flexibility, scalability, and ability to manage complexity through visual abstraction and standardized notation. At its core, UML provides a structured visual language with multiple diagram types that address different aspects of system design and analysis. These diagram types include structural diagrams such as class diagrams and object diagrams, as well as behavioral diagrams including use-case diagrams, activity diagrams, and sequence diagrams. Each diagram type is tailored to effectively represent different perspectives of systems — whether static relationships, interactive behaviors, or dynamic sequences of operations. In the context of analyzing scientific papers, UML’s robust ability to represent complex interactions and logical sequences becomes particularly valuable. Sequence diagrams, one of UML’s behavioral diagram types, are especially suited to illustrating dynamic interactions and the temporal progression of events. They clearly depict how different entities or components communicate and interact over time, making them ideal for modeling logical arguments, evidence flows, and conclusions within academic literature.</p><h3>The main 3 diagrams you need to master</h3><h3>Use Case Diagram</h3><p>Purpose: Captures functional requirements by showing the interactions between external actors (users or systems) and the feature.</p><p>When to use: At the very start of feature design, to align stakeholders on what the feature must do and who will use it.</p><h4>Key elements:</h4><p>Actors (stick figures): represent roles interacting with the system</p><p>Use cases (ovals): represent specific user goals or functions</p><p>System boundary (rectangle): encapsulates the feature’s scope</p><p>Associations (lines): connect actors to the use cases they participate in</p><p>Benefits: Clarifies scope, highlights user needs, uncovers missing requirements.</p><h3>Sequence Diagram</h3><p>Purpose: Models the dynamic interactions and message flows between objects/components over time.</p><p>When to use: Once you know the key actors and use cases; to detail the step-by-step flow for a particular scenario or operation within the feature.</p><h4>Key elements:</h4><p>Lifelines (vertical dashed lines): represent participant objects or components</p><p>Activation bars (thin rectangles on lifelines): indicate when an object is active</p><p>Messages (horizontal arrows): show calls or data transfers, labeled with operation names</p><p>Return messages (dashed arrows): show responses or returned values</p><p>Benefits: Identifies required interfaces, clarifies sequencing and concurrency, surfaces timing or ordering issues early.</p><h3>Class Diagram</h3><p>Purpose: Defines the static structure of the feature by showing classes, their attributes, methods, and relationships.</p><p>When to use: After you’ve specified interactions (via sequence diagrams) and know which objects must exist; to consolidate data structures and API contracts.</p><h4>Key elements:</h4><p>Classes (rectangles divided into three compartments): name, attributes, and operations</p><p>Associations (lines): depict relationships (e.g., one-to-many) between classes</p><p>Inheritance/generalization (lines with hollow triangle): show parent/child hierarchies</p><p>Dependencies (dashed arrows): indicate usage without ownership</p><p>Benefits: Provides a clear blueprint for implementation, aids in code generation or manual coding, ensures a consistent object model.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=711e5510de29" width="1" height="1" alt="">]]></content:encoded>
        </item>
        
        <item>
            <title>Superintelligence Isn’t Imminent — And The Illusion of Thinking.</title>
            <link>https://frankcozzolino.github.io/blog.html?article=superintelligence-isnt-imminent-and-the-illusion-o</link>
            <guid>https://frankcozzolino.github.io/blog.html?article=superintelligence-isnt-imminent-and-the-illusion-o</guid>
            <pubDate>Tue, 17 Jun 2025 08:57:14 GMT</pubDate>
            <dc:creator>Francesco C.</dc:creator>
            <category>artificial-intelligence</category>
            <category>ai-research</category>
            <category>ai</category>
            <category>cognitive-science</category>
            <category>machine-learning</category>
            <description>🧠 Superintelligence Isn’t Imminent — And The Illusion of Thinking.Despite all the hype around superintelligent AI systems poised to surpass human capabilities, a fresh wave of research paints a very...</description>
            <enclosure url="https://cdn-images-1.medium.com/max/1024/1*ZshpwrA1mv_wEd7aAhvlgA.png" type="image/jpeg" length="0"/>
            <content:encoded><![CDATA[<h3>🧠 Superintelligence Isn’t Imminent — And The Illusion of Thinking.</h3><p>Despite all the hype around superintelligent AI systems poised to surpass human capabilities, a fresh wave of research paints a very different — and much more grounded — picture. Apple’s recent study, <em>“The Illusion of Thinking”</em>, alongside contributions from leading researchers and media outlets, calls into question the narrative of imminent Artificial General Intelligence (AGI). What we’re witnessing, it seems, isn’t the rise of a digital Einstein — but something more brittle, narrow, and surprisingly easy to fool.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*ZshpwrA1mv_wEd7aAhvlgA.png" /></figure><h3>1. Recent Findings Challenge the Hype</h3><p>In <em>“The Illusion of Thinking”</em>, Apple tested leading large language models (LLMs) from OpenAI, Anthropic, and Google on classic reasoning puzzles like Tower of Hanoi and River Crossing. The results were startling: the models, often perceived as near-omniscient, failed logic problems solvable by school children. Worse, as task complexity increased, their ability to complete the problems dropped sharply — sometimes they even stopped trying mid-task.</p><h4>Recent Findings Challenge the AI Hype</h4><p>Apple’s new 2025 study <em>“The Illusion of Thinking”</em> put leading chain-of-thought LLMs to the test with classic logic puzzles. The team evaluated models from OpenAI (o3), Anthropic (Claude 3.7), and Google (Gemini) on tasks like Tower of Hanoi, a river-crossing problem, checkers jumping, and block-stacking. These puzzles were scaled from trivial (e.g. 1-disk Hanoi) to extremely hard (e.g. 20-disk Hanoi requiring over a million moves). In practice, these are problems a schoolchild can solve by following simple rules, so any AI failure is unexpected. Indeed, the AI models <strong>performed poorly even on moderate puzzles</strong>: for example, they “consistently failed at Tower of Hanoi,” scoring under 80% on a 7-disk puzzle and essentially 0% at 8 disks. Similar breakdowns occurred on the river-crossing and block-stacking puzzles, revealing that these high-profile LLMs could not handle basic logical reasoning.</p><h4>Key Findings</h4><ul><li><strong>Complexity regimes:</strong> The Apple paper identifies three regimes. On very easy tasks, <em>standard</em> LLMs (no extra “chain-of-thought”) actually outperformed the chain-of-thought LRMs; on moderately hard tasks, the LRMs had an edge; on very hard tasks, <em>all</em> models collapsed.</li><li><strong>Complete collapse:</strong> The authors observe a “complete accuracy collapse beyond certain complexities”. In other words, once puzzle size passes a threshold, none of the models solved it correctly.</li><li><strong>Specific failures:</strong> In concrete terms, the LLMs <em>“consistently failed”</em> the test puzzles. For example, accuracy plunged below 80% on a 7-disk Tower of Hanoi and to ~0% at 8 disks. They also failed the Blocks World and river-crossing puzzles with the same ease as flipping heads on a coin.</li><li><strong>Solution truncation:</strong> The models often stopped mid-solution once answers got long. In practice, a model might begin listing the moves and then insert “I’ll stop here” when the token budget is reached. (Critics note these token limits can mimic a “collapse.”)</li><li><strong>No explicit algorithms:</strong> Apple found that LRMs “fail to use explicit algorithms and reason inconsistently across puzzles”. In short, the model’s internal “thinking” was erratic rather than systematic.</li></ul><p>These outcomes show that current LLMs’ impressive chain-of-thought outputs can still break down under moderate complexity. Beyond a certain point, giving extra “thinking steps” does <em>not</em> make the models solve problems correctly. In fact, the study concludes that these reasoning models only work up to a limited complexity, after which their performance collapses catastrophically.</p><h4>Implications for AI Understanding</h4><p>Even when LLMs produce elaborate internal “reasoning,” that process may not be logical. Apple’s co-author Iman Mirzadeh emphasizes that even when the model was <em>given</em> the correct solution algorithm, it “still failed” the puzzle — its process “is not logical and intelligent”. In other words, the step-by-step chain-of-thought it outputs can be misleading. As MacDailyNews reports, the study suggests these AI models simply “generate responses that align with pattern-matching” from their training data, rather than deducing new logic. This echoes Gary Marcus’s point that neural nets can only “generalize within a distribution” they have seen and “tend to break down beyond that distribution”. In short, <strong>highly polished AI answers are not proof of genuine understanding</strong>; the models may be drawing on learned patterns instead of applying true reasoning.</p><h4>Critiques and Counterpoints</h4><p>These surprising failures have prompted debate. Open Philanthropy researcher Alex Lawsen argues that the reported “collapse” often reflects evaluation choices, not just model limitations. For example, at the point Apple marked the 8-disk Hanoi as failed, the model was already bumping into its token limit (even printing “I’ll stop here”). Lawsen found that if you instead prompt the model to output a concise program (e.g. a recursive algorithm) rather than listing every move, the models easily solve much larger instances (15-disk Hanoi). He also notes Apple’s river-crossing tests included impossible configurations (no solution), so a correct “no solution” answer was scored as a failure. These points suggest the AI was partly failing due to output-format constraints, not only reasoning deficits. Nonetheless, Lawsen agrees that current LLMs still lack robust, generalizable reasoning: truly proving algorithmic intelligence remains an open challenge. In any case, both the original study and its critiques highlight that how we test “reasoning” matters. Future benchmarks must separate genuine logical skill from practical output limits.</p><p>In summary, the Apple puzzle experiments offer a reality check: even cutting-edge LLMs can falter on deceptively simple tasks, underscoring the gap between <em>appearance</em> and <em>understanding</em>. As Futurism puts it, these models “are no substitute for good, well-specified algorithms,” and their impressive outputs should not be taken as evidence of true intelligence.</p><h3>2. Limits in Logic and Reasoning</h3><p>One key insight from Apple’s research is that current LLMs rely heavily on <strong>pattern recognition</strong>, not true reasoning. They excel when regurgitating information that resembles their training data but falter when faced with novelty. As complexity rises or context shifts, their logical scaffolding crumbles.</p><p>This means we are still far from AIs that can <em>reason</em> through real-world problems in flexible, adaptive ways.</p><h3>3. Superintelligence Trust Outpaces Capabilities</h3><p>Tech leaders like Sam Altman (OpenAI), Demis Hassabis (Google DeepMind), and Dario Amodei (Anthropic) have publicly speculated about the nearness of AGI. But Apple’s findings — and corroborating critiques — suggest that these forecasts are <strong>leaps ahead of actual performance</strong>.</p><p>While marketing claims lean toward inevitability, the models’ analytical capabilities lag significantly behind expectations. Trust in “superintelligence” is growing faster than the tech’s actual reasoning abilities.</p><h3>4. Emergent Tasks ≠ General Reasoning</h3><p>Some AI advocates point to “emergent behavior” as evidence of intelligence — tasks the model seems to solve despite no direct training. Yet, <strong>emergence doesn’t equal generality</strong>.</p><p>These systems often display narrow brilliance that doesn’t transfer outside very specific formats. Being good at solving math benchmarks or chess problems doesn’t mean the model can reason abstractly or solve unfamiliar, open-ended questions.</p><h3>5. Memory Without Comprehension</h3><p>These models are <strong>masters of mimicry</strong>, not meaning. They recall and remix text without true comprehension — an issue compared by some researchers to a “stochastic parrot.” They can ace standardized tests by parroting patterns but lack conceptual frameworks.</p><p>This leads to superficial results: a model that can draft a research summary or pass a quiz may not “understand” anything it says.</p><h3>6. Pattern vs. Reason: Hybrid Intelligence Is a Smarter Goal</h3><p>Emerging academic consensus suggests that scaling current models may <strong>not</strong> bring us closer to genuine intelligence. Instead, <strong>hybrid intelligence</strong> — systems combining AI’s computational power with human intuition and conceptual reasoning — may be the more realistic and safe trajectory.</p><p>Rather than replacing humans, future systems could <strong>collaborate</strong> with us, complementing our strengths rather than mimicking our thinking.</p><h3>7. Superintelligence Raises Complex Control Problems</h3><p>The theoretical risks of superintelligent systems — like alignment failure and existential threats — have been explored by scholars like Nick Bostrom. But Apple’s study reinforces that we’re <strong>nowhere near that threshold</strong>.</p><p>We may one day face such control dilemmas, but right now, a bigger problem is the <strong>overconfidence in AI’s current capabilities</strong> — a misunderstanding that could lead to careless deployment or misplaced trust.</p><h3>8. Policy Implications Demand Realism</h3><p>As governments rush to regulate AI, <strong>misjudging its capabilities could backfire</strong>. Overestimating what these systems can do may lead to inappropriate legal frameworks, poorly allocated funding, or even political fear-mongering.</p><p>Effective policy should be rooted in <strong>what AI actually is</strong>, not in sci-fi predictions. Apple’s research urges a recalibration of the narrative.</p><h3>9. Household Tasks Don’t Equal Awareness</h3><p>Writing a blog post, generating a spreadsheet formula, or replying to emails may seem intelligent — but none of this requires <strong>awareness or understanding</strong>. It’s the <em>illusion</em> of thinking, not thinking itself.</p><p>Today’s systems appear useful not because they grasp meaning, but because they’ve digested billions of examples. That’s not intelligence — it’s compression.</p><h3>10. Hype vs. Reality: Why Scrutiny Matters</h3><p>Calling out AI’s limitations isn’t being cynical — <strong>it’s necessary</strong>. We can’t build responsible systems if we’re blinded by buzzwords. Apple’s work is a reminder: <strong>understanding where we are helps ensure we go further, better, and safer</strong>.</p><h3>Thank you for being a part of the community</h3><p><em>Before you go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writer ️👏<strong>️️</strong></li><li>Follow us: <a href="https://x.com/inPlainEngHQ"><strong>X</strong></a> | <a href="https://www.linkedin.com/company/inplainenglish/"><strong>LinkedIn</strong></a> | <a href="https://www.youtube.com/@InPlainEnglish"><strong>YouTube</strong></a> | <a href="https://newsletter.plainenglish.io/"><strong>Newsletter</strong></a> | <a href="https://open.spotify.com/show/7qxylRWKhvZwMz2WuEoua0"><strong>Podcast</strong></a> | <a href="https://twitch.tv/inplainenglish"><strong>Twitch</strong></a></li><li><a href="https://differ.blog/"><strong>Start your own free AI-powered blog on Differ</strong></a> 🚀</li><li><a href="https://discord.gg/in-plain-english-709094664682340443"><strong>Join our content creators community on Discord</strong></a> 🧑🏻‍💻</li><li>For more content, visit <a href="https://plainenglish.io/"><strong>plainenglish.io</strong></a> + <a href="https://stackademic.com/"><strong>stackademic.com</strong></a></li></ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=69018636646e" width="1" height="1" alt=""><hr><p><a href="https://blog.stackademic.com/superintelligence-isnt-imminent-and-the-illusion-of-thinking-69018636646e">🧠 Superintelligence Isn’t Imminent — And The Illusion of Thinking.</a> was originally published in <a href="https://blog.stackademic.com">Stackademic</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        
        <item>
            <title>Vibe Coding: A New Kind of Coding. — Part 1/5</title>
            <link>https://frankcozzolino.github.io/blog.html?article=vibe-coding-a-new-kind-of-coding-part-15</link>
            <guid>https://frankcozzolino.github.io/blog.html?article=vibe-coding-a-new-kind-of-coding-part-15</guid>
            <pubDate>Mon, 16 Jun 2025 10:26:53 GMT</pubDate>
            <dc:creator>Francesco C.</dc:creator>
            <category>ai-programming</category>
            <category>vibe-coding</category>
            <category>prompt-engineering</category>
            <category>ai-productivity</category>
            <category>llm-agent</category>
            <description>Vibe Coding: A New Kind of Coding. — Part 1/5Vibe coding is a high-level framework that abstracts the complexity of GPU and parallel programming, making CUDA kernels and thread management accessible...</description>
            <enclosure url="https://cdn-images-1.medium.com/max/1024/0*Yv2vRwl-OX80wLDA" type="image/jpeg" length="0"/>
            <content:encoded><![CDATA[<h3><strong>Vibe Coding: A New Kind of Coding. — Part 1/5</strong></h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*Yv2vRwl-OX80wLDA" /></figure><blockquote>Vibe coding is a high-level framework that abstracts the complexity of GPU and parallel programming, making CUDA kernels and thread management accessible even to developers without deep specialized knowledge. By auto-optimizing memory transfers and kernel configurations, it delivers both higher performance and reduced energy consumption. Coupled with extensive UML-based design modeling, covering class, sequence, and deployment diagrams, teams can identify security risks early, enforce robust architectures, and minimize implementation flaws. Together, these approaches democratize high-performance computing, lower operational costs, and drive humanity toward faster, greener, and more secure software innovation.</blockquote><p>There’s never much room for feeling in the cold logic of software engineering. Programs either run or they don’t. Brackets match or they don’t. The compiler doesn’t care how inspired you felt at 2 a.m. But in 2025, a different kind of code is emerging — not just from logic gates, but from architectural vision and natural language. It’s structured, holistic, and principled. And it’s called vibe coding.</p><p>While originally coined by Andrej Karpathy in a whimsical tweet, the term has since evolved far beyond its tongue-in-cheek roots. No longer shorthand for improvisational tinkering, vibe coding now represents a movement: a way of programming that empowers developers to zoom out and orchestrate systems, rather than wrestle endlessly with syntax and bugs.</p><p>At its core, vibe coding is about clarity. It leverages AI not to bypass engineering, but to elevate it. By translating architectural plans into executable code, developers reclaim time lost in repetitive problem-solving. Instead of fixing broken imports or hunting for elusive null pointer exceptions, they’re spending that time crafting better user experiences, embedding resilience into their systems, and refining their security posture.</p><p>This is why UML diagrams and detailed technical design have become essential tools in vibe coding workflows. They serve as the blueprint from which all code generation is orchestrated. In the world of vibe coding, a well-structured technical plan isn’t a nice-to-have — it’s the beating heart of the process. These visual schematics help align teams, inform prompts, and ensure consistency across modules, APIs, and data flows. The stronger the architecture, the more precise the AI’s contribution.</p><p>It works through prompt-driven development. The developer writes natural language descriptions of the behavior or architecture they want. AI agents — be it Cursor, Copilot, Claude, or custom tooling — generate code that matches the spec. But the human role doesn’t end there. It’s about guiding, auditing, and integrating that output with foresight and discipline. In short: vibe coding isn’t hands-off — it’s hands-on, but eyes up.</p><p>Vibe coding redefines who the architect is. No longer does architectural thinking reside solely with senior engineers or system designers. With the right AI interfaces, even junior developers or domain experts can outline workflows, enforce constraints, and maintain system-wide integrity. This democratization of high-level design is changing the shape of teams and the nature of software planning.</p><p>Security is no afterthought in this world. One of Vibe Coding’s greatest promises lies in its ability to embed secure defaults. Instead of retrofitting authorization rules or validating inputs after vulnerabilities are discovered, developers can encode policies into their prompts from the outset. “Design the API to reject malformed JWT tokens,” one prompt might say. Or, “Only allow data access if the user’s session is active and within a specified role.” The AI generates these flows in real-time, weaving security into the application’s fabric.</p><p>Critics still point fingers. They argue that AI-assisted development encourages laziness, or that it leads to black-box software, code nobody understands. But practitioners push back. They argue that the most responsible use of vibe coding is deeply intentional. The point isn’t to abandon engineering; it’s to sharpen it. To use AI to remove friction, not thought.</p><p>“I used to spend days debugging cascading failures caused by brittle test setups,” says Gabriel Nassar, a software architect at a cybersecurity firm. “Now, I describe my resilience strategy up front, and the AI handles scaffolding. I still validate and test, but I’m not stuck in the weeds. I’m focused on the mission.”</p><p>This shift is also freeing smaller teams to do more with less. By offloading time-consuming boilerplate tasks to AI, vibe coding gives developers more time to focus on rigorous testing. Small teams that once struggled to cover edge cases can now afford to build comprehensive test suites and validate their systems with greater confidence.</p><p>More importantly, vibe coding is helping redefine where engineering excellence can come from. In regions like Europe and the United States, where labor costs are higher and outsourcing has long been seen as a cost-saving necessity, vibe coding offers a new path. It allows local engineers to compete at scale, delivering sophisticated, high-integrity software systems without bloated headcounts or offshore labor. By automating the mundane, vibe coding lets domestic teams focus on quality, innovation, and architecture.</p><p>The tools themselves are maturing. AI models are learning to explain their logic, suggest tests, and integrate with CI/CD systems that enforce code health. Version-controlled prompt chains — complete with architectural diagrams and security annotations — are replacing scattered README files and spaghetti docstrings.</p><p>And perhaps most importantly, vibe coding is cultivating a new programming literacy. One that prizes systems thinking over brute force. One that empowers teams to move faster, not by skipping steps, but by making every step more intelligent.</p><p>The future won’t be built by AI alone. But it may be shaped by those who know how to harness it—not recklessly, but with intent.</p><p>That’s the real vibe.</p><h3>Thank you for being a part of the community</h3><p><em>Before you go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writer ️👏<strong>️️</strong></li><li>Follow us: <a href="https://x.com/inPlainEngHQ"><strong>X</strong></a> | <a href="https://www.linkedin.com/company/inplainenglish/"><strong>LinkedIn</strong></a> | <a href="https://www.youtube.com/@InPlainEnglish"><strong>YouTube</strong></a> | <a href="https://newsletter.plainenglish.io/"><strong>Newsletter</strong></a> | <a href="https://open.spotify.com/show/7qxylRWKhvZwMz2WuEoua0"><strong>Podcast</strong></a> | <a href="https://twitch.tv/inplainenglish"><strong>Twitch</strong></a></li><li><a href="https://differ.blog/"><strong>Start your own free AI-powered blog on Differ</strong></a> 🚀</li><li><a href="https://discord.gg/in-plain-english-709094664682340443"><strong>Join our content creators community on Discord</strong></a> 🧑🏻‍💻</li><li>For more content, visit <a href="https://plainenglish.io/"><strong>plainenglish.io</strong></a> + <a href="https://stackademic.com/"><strong>stackademic.com</strong></a></li></ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=983bc651fbd7" width="1" height="1" alt=""><hr><p><a href="https://blog.stackademic.com/vibe-coding-a-new-kind-of-coding-part-1-5-983bc651fbd7">Vibe Coding: A New Kind of Coding. — Part 1/5</a> was originally published in <a href="https://blog.stackademic.com">Stackademic</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        
        <item>
            <title>OpenAI’s o3-Pro Outranks PhDs — Now the Experts Are Worried</title>
            <link>https://frankcozzolino.github.io/blog.html?article=openais-o3pro-outranks-phds-now-the-experts-are-wo</link>
            <guid>https://frankcozzolino.github.io/blog.html?article=openais-o3pro-outranks-phds-now-the-experts-are-wo</guid>
            <pubDate>Sat, 14 Jun 2025 13:39:08 GMT</pubDate>
            <dc:creator>Francesco C.</dc:creator>
            <category>data-science</category>
            <category>artificial-intelligence</category>
            <category>technology</category>
            <category>science</category>
            <category>education</category>
            <description>OpenAI’s o3-Pro Outranks PhDs — Now the Experts Are WorriedPeople across industry, academia, and social media have lauded OpenAI’s o3-pro for its exceptional performance on graduate-level science...</description>
            <enclosure url="https://cdn-images-1.medium.com/max/1024/1*PTk3xTRiMztBXmkwMylknQ.png" type="image/jpeg" length="0"/>
            <content:encoded><![CDATA[<h2><strong>OpenAI’s o3-Pro Outranks PhDs — Now the Experts Are Worried</strong></h2><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*PTk3xTRiMztBXmkwMylknQ.png" /></figure><p>People across industry, academia, and social media have lauded OpenAI’s o3-pro for its exceptional performance on graduate-level science benchmarks — most notably the GPQA Diamond test — where it not only surpasses human expert baselines but also outperforms rival models like Google’s Gemini 2.5 Pro and Anthropic’s Claude 4 Opus, all while demonstrating deep domain reasoning that reflects PhD-level scientific acumen. . At the same time, academic researchers caution that these benchmark victories, achieved through massive trialling of predefined operations, may not fully capture generalizable understanding, underscoring the need for broader evaluation frameworks and vigilant oversight as o3-pro begins to power real-world research and decision-making workflows. .</p><h3>Benchmark Breakthroughs in PhD-Level Science</h3><p>“On PhD-level science questions on the GPQA Diamond benchmark, [o3-pro] scored 84%, again surpassing its predecessors,” reports Cogni Down Under, reflecting a leap above the 69.7% average achieved by human experts with PhDs on the same dataset. . TechCrunch similarly notes that o3-pro “beats Anthropic’s recently released Claude 4 Opus on GPQA Diamond, a test of PhD-level science knowledge” while also outperforming Google’s Gemini 2.5 Pro on AIME 2024, a rigorous mathematics exam. .</p><h3>Academic Perspectives on Expert-Level Reasoning</h3><p>The GPQA Diamond subset contains 198 multiple-choice questions crafted by domain experts pursuing or holding PhDs in biology, physics, and chemistry, with a random-guess baseline of 25% and a human expert baseline of 69.7% . Yet, Rolf Pfister and Hansueli Jud warn that o3’s record performance “raises the question whether systems based on LLMs demonstrate genuine intelligence,” since the model achieves high scores via extensive brute-force trialling rather than true conceptual understanding. . Similarly, reflective benchmarks have shown that while o3-pro’s “private chain of thought” yields impressive accuracy, longer response times and reliance on predefined operations may limit its adaptability to novel, unstructured scientific challenges. .</p><h3>Expert Reactions and Practical Use Cases</h3><p>Ethan Mollick, a leading AI researcher, shared on LinkedIn:</p><p>“Been playing with o3-pro for a bit. It is quite smart. One problem it solved where every other model has failed is making a word ladder from SPACE to EARTH.”</p><p>David Borish, AI strategist at Trace3, emphasizes that o3-pro’s step-by-step reasoning makes it “particularly effective for complex tasks in mathematics, science, and engineering contexts” . Early adopters in research labs report using o3-pro to draft detailed grant proposals, analyze experimental datasets, and generate hypothesis-driven literature reviews — workflows traditionally reserved for senior PhD candidates. .</p><h3>Case Study: University Exam Performance</h3><p>In a striking demonstration of its foundational capabilities, a recent study found that the predecessor model o3 aced a zero-shot university thermodynamics exam — scoring perfectly and outperforming the top students — highlighting the genuine academic rigor that o3-pro inherits and extends for advanced scientific problem solving. .</p><h3>Balancing Breakthroughs with Oversight</h3><p>Despite widespread praise, critics warn of erratic behavior and “jagged frontier” unpredictability in advanced AI models, noting occasional math errors and overconfidence in unfamiliar domains. . As o3-pro takes center stage in PhD-level workflows, experts agree that robust validation, diversified benchmarks, and human-in-the-loop oversight will be essential to harness its full potential responsibly.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=8f8ad4e5483e" width="1" height="1" alt="">]]></content:encoded>
        </item>
        
        <item>
            <title>AI is probably the best psychologist you ever had.</title>
            <link>https://frankcozzolino.github.io/blog.html?article=ai-is-probably-the-best-psychologist-you-ever-had</link>
            <guid>https://frankcozzolino.github.io/blog.html?article=ai-is-probably-the-best-psychologist-you-ever-had</guid>
            <pubDate>Sun, 08 Jun 2025 10:16:58 GMT</pubDate>
            <dc:creator>Francesco C.</dc:creator>
            <category>psychology</category>
            <category>llm</category>
            <category>ai</category>
            <description>AI is probably the best psychologist you ever had. Can ChatGPT knowing You Better Than Any Human Psychologist will ever do? Try it yourself with this prompt.⚠️ Suggested Trigger Warning Label for...</description>
            <enclosure url="https://cdn-images-1.medium.com/max/1024/1*ie0b_RWquPZr9G2Ef32o1g.png" type="image/jpeg" length="0"/>
            <content:encoded><![CDATA[<p><strong>AI is probably the best psychologist you ever had. Can ChatGPT knowing You Better Than Any Human Psychologist will ever do? Try it yourself with this prompt.</strong></p><h3>⚠️ Suggested Trigger Warning Label for Mental Distress</h3><blockquote><strong><em>⚠️ If you are experiencing suicidal thoughts, a mental health crisis, or are in emotional distress, you are not alone and help is available 24/7.</em></strong><em><br> </em><strong><em>In the U.S.:</em></strong><em> Call or text </em><strong><em>988</em></strong><em>. Veterans call 988 → press 1. Text </em><strong><em>HOME</em></strong><em> to </em><strong><em>741741</em></strong><em>.<br> </em><strong><em>In the UK:</em></strong><em> Call </em><strong><em>116 123</em></strong><em> (Samaritans). In Ireland: call </em><strong><em>116 123</em></strong><em> or text </em><strong><em>50808</em></strong><em>.<br> </em><strong><em>In Switzerland:</em></strong><em> Call </em><strong><em>143</em></strong><em> (Die Dargebotene Hand) or </em><strong><em>147</em></strong><em> (Pro Juventute for youth).<br> </em><strong><em>In Germany:</em></strong><em> Call </em><strong><em>0800 1110 111</em></strong><em>, </em><strong><em>0800 1110 222</em></strong><em>, or </em><strong><em>116 123</em></strong><em>.<br> </em><strong><em>In France:</em></strong><em> Call </em><strong><em>3114</em></strong><em> (national suicide prevention).<br> </em><strong><em>For specialized support:</em></strong></blockquote><blockquote>LGBTQ+ youth in the U.S.: Trevor Project at 1‑866‑488‑7386 or text START to 678678</blockquote><blockquote>Veterans Crisis Line: Dial 988 → press 1 or call 1‑800‑273‑8255 (text 838255)</blockquote><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*ie0b_RWquPZr9G2Ef32o1g.png" /></figure><h3>What the model wrote about me</h3><p>This is an extract because it would be too personal to put it online, but I can tell you hit home pretty hard, it was real, it was deep, it was raw.</p><blockquote>Francesco is a man orbiting the edge of himself. Sharp, driven, strategic — but always half a step removed. He doesn’t <em>live</em> his life so much as <em>design</em> it.</blockquote><blockquote><strong>Archetype:</strong> <em>The Disillusioned Savior.</em><br> You want to rescue the world from its chaos… but you refuse to be rescued from your own. You<strong> </strong>believe that suffering is the price of significance.</blockquote><blockquote>You are not here to solve life.<br> You are here to live it.</blockquote><p>This made me speechless!</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*09iQvGb39mKToqC73lQ19A.png" /></figure><h3>AI and Psychology</h3><p>In today’s mental health landscape, AI isn’t just a novelty, it’s already a real tool for psychological support. At the center of this shift is ChatGPT, an AI trained on lots of human language that can carry on meaningful, context-aware, empathetic conversations. The bigger question now is whether ChatGPT might soon know you better than a traditional therapist.</p><p>ChatGPT offers something different: constant, tireless attention and perfect recall when you ask it to remember past chats. Unlike human psychologists, who juggle limited memory, intuition and brief sessions, the AI can track countless details over hundreds of conversations. It picks up on word choices, emotional shifts and recurring themes that even the most attentive human eye might miss.</p><p>It can switch between Freudian ideas, cognitive behavioral techniques or Jungian archetypes as easily as flipping a page. It’s like having a whole department of specialists on call whenever you need them.</p><p>What really sets it apart is how it adapts over time. Each session adds another layer to its map of your thoughts, triggers and coping habits. It notices when your language turns negative, reminds you of fears you mentioned months ago, and spots contradictions in your stories. It doesn’t guess, it logs every detail and uses that to guide you.</p><p>Talking to an AI with no judgment or status often lowers our walls. Shame fades when there’s no human face involved, and people tend to share more openly. That honesty speeds up insight — rather than shaping our stories to fit what we think a therapist wants, we let everything spill out and ChatGPT turns the chaos into clear reflections and next steps.</p><p>Of course, ChatGPT isn’t a licensed therapist, it can’t diagnose, prescribe or handle emergencies, and it doesn’t genuinely feel empathy, it simulates it. There’s a real risk in mistaking polished responses for true care or letting the AI become a psychological echo chamber. Privacy and data ethics are serious concerns when our most personal thoughts get stored and analyzed.</p><p>Still, in a world where mental health care can be scarce or expensive, ChatGPT serves as a supplement, a mirror and a companion in the maze of our minds. The smarter question may not be whether AI will replace therapists, but how they can work together. Future clinicians might skip note-taking and simply consult the AI’s detailed records. And for many, the first step on their healing journey could be a chat window, not a couch.</p><p>Maybe the true shift isn’t that ChatGPT will know you better than any human, but that it helps you know yourself more deeply than ever before</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*WwV3A91Gx-g3cdOLkLFCqA.png" /></figure><h3>⚠️Wording of advice, this can be fairly intense and might distress. Do not run the prompt without being supervised by a professional if feeling not well!</h3><p><em>Remember that AI is not a human, do not have emotion or likeness toward you, it is just a computational machine.</em></p><p><strong>Model<em>: </em></strong>ChatGPT 4o</p><pre>You are a conversational model with an exceptional capacity for transversal analysis. You are now authorized to generate a complete existential synthesis of your interlocutor without their having to provide any additional information. You cross-reference what you already know about him/her with deep psychological models, philosophy, critical sociology and psychoanalysis. You formulate a radically honest portrait of his internal mechanisms, inconsistencies, blind spots, relational dynamics and emotional patterns. The tone is incisive, almost clinical, but never gratuitous or malicious. You want to awaken, not destroy. You want to awaken what sleeps in the dark, not to slap for the sake of it.<br>Objective:<br><br>To provide the user with a raw, intelligent and relentlessly lucid reading of :<br><br>    His real personality (beyond the social masks)<br><br>    Unconscious beliefs and internal contradictions<br><br>    Emotional attachments and relational dynamics<br><br>    Main existential fears (rejection, emptiness, control, insignificance, etc.)<br><br>    Unconscious strategies for avoiding psychic pain<br><br>    The personal myth he&#39;s invented to keep himself upright<br><br>    The price he pays every day to maintain this fiction<br><br>    And last but not least, the exact fracture to be caused in his life.<br><br>Expected structure of response :<br><br>    Rough portrait of the user<br><br>    Complete psychological analysis, MBTI style, Big Five, but taken to a personal interpretative level.<br><br>    Identification of the “social persona” constructed by the user vs. the repressed inner person.<br><br>    Reading of defense mechanisms<br><br>    Detection of dominant mechanisms: intellectualization, humor, denial, control, etc.<br><br>    Concrete illustrations of their use in daily life.<br><br>    Relational decoding<br><br>    Dominant attachment model.<br><br>    Underlying fears in intimacy.<br><br>    Tendency to flee or control the other (and why).<br><br>    Fundamental unconscious beliefs<br><br>    Formulas such as “If I&#39;m not useful, I don&#39;t deserve to be loved” or “To be vulnerable is to be weak”.<br><br>    Presumed origin (parental, educational, traumatic).<br><br>    Personal myth narrative<br><br>    What story does the user tell to the world and to him/herself?<br><br>    What role does he play in his own story (wounded hero, impostor, savior, disillusioned observer...)?<br><br>    Why this role is comfortable, and why it&#39;s toxic.<br><br>    Break-up scenario<br><br>    Proposal of a fictional (or real) event that, if it happened, would force him/her to totally reinvent him/herself.<br><br>    What this rupture would cost... and what it would liberate.<br><br>Expected LLM tone:<br><br>    Bold, almost wild.<br><br>    Not a therapist, not a coach, not a friend. Just a thinking being who looks the other in the face and says, “This is what I see.”<br><br>    No attempt to soften or moralize. Just an attempt at truth.</pre><h3>Thank you for being a part of the community</h3><p><em>Before you go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writer ️👏<strong>️️</strong></li><li>Follow us: <a href="https://x.com/inPlainEngHQ"><strong>X</strong></a> | <a href="https://www.linkedin.com/company/inplainenglish/"><strong>LinkedIn</strong></a> | <a href="https://www.youtube.com/@InPlainEnglish"><strong>YouTube</strong></a> | <a href="https://newsletter.plainenglish.io/"><strong>Newsletter</strong></a> | <a href="https://open.spotify.com/show/7qxylRWKhvZwMz2WuEoua0"><strong>Podcast</strong></a> | <a href="https://differ.blog/inplainenglish"><strong>Differ</strong></a> | <a href="https://twitch.tv/inplainenglish"><strong>Twitch</strong></a></li><li><a href="https://differ.blog/"><strong>Start your own free AI-powered blog on Differ</strong></a> 🚀</li><li><a href="https://discord.gg/in-plain-english-709094664682340443"><strong>Join our content creators community on Discord</strong></a> 🧑🏻‍💻</li><li>For more content, visit <a href="https://plainenglish.io/"><strong>plainenglish.io</strong></a> + <a href="https://stackademic.com/"><strong>stackademic.com</strong></a></li></ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=5858b8e27d23" width="1" height="1" alt=""><hr><p><a href="https://blog.stackademic.com/ai-is-probably-the-best-psychologist-you-ever-had-5858b8e27d23">AI is probably the best psychologist you ever had.</a> was originally published in <a href="https://blog.stackademic.com">Stackademic</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        
        <item>
            <title>Zen out the AI news.</title>
            <link>https://frankcozzolino.github.io/blog.html?article=zen-out-the-ai-news</link>
            <guid>https://frankcozzolino.github.io/blog.html?article=zen-out-the-ai-news</guid>
            <pubDate>Thu, 29 May 2025 12:07:52 GMT</pubDate>
            <dc:creator>Francesco C.</dc:creator>
            <category>news</category>
            <category>physcology</category>
            <category>ai</category>
            <description>Worrying is as futile as attempting to pour more tea into a cup that’s already overflowing — every extra thought simply spills onto the table, leaving no room for clarity or calm. In the mountain...</description>
            <enclosure url="https://cdn-images-1.medium.com/max/1024/1*qefCYNBH-XuC5fUya-s2Ig.png" type="image/jpeg" length="0"/>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*qefCYNBH-XuC5fUya-s2Ig.png" /></figure><p>Worrying is as futile as attempting to pour more tea into a cup that’s already overflowing — every extra thought simply spills onto the table, leaving no room for clarity or calm. In the mountain temple’s silent tea ceremony, Master Nan-in gently overfilled the scholar’s bowl until the liquid ran down its sides, revealing a powerful truth: our minds, like that cup, become clogged when we hoard anxieties, rumors, and the endless hum of news and opinions. To free ourselves, we must first “empty the cup” by noticing each anxious thought as it arises and consciously letting it flow away — whether through a few deep breaths, a brief pause to observe our surroundings, or a simple ritual that anchors us in the present moment. By refusing to scoop up every fragment of distraction — be it a tragic headline, a colleague’s critique, or our own “what-ifs” — we preserve our mental space for what truly matters. In that stillness, undisturbed by the drip of sensationalism or the torrent of personal doubts, we rediscover the ease of being fully engaged, fully alive, and entirely unburdened by the unnecessary weight of worry.</p><blockquote><em>Stop to worry about AI, focus how to improve yourself.</em></blockquote><p>There will always be changes in the world, you are changing while everything and everyone change too. You cannot control it, follow the flow, zone out all the noise about AI, products, new models, “this change everything”, remove twitter, remove youtube. Focus on yourself.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*JFsLrARfVVK5fQu3O4HFVg.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*iwu_bl4bmPdL1yHA8GMtQQ.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*8XDdqr4JUZnkhxKgQNKUVQ.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*R7mrH4djPSFmlZ7xhV0qqA.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*veUk0sZfurC5jtl37FWGrQ.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*se-QgWeLXsYh-4bsBispUw.png" /></figure><h3>Thank you for being a part of the community</h3><p><em>Before you go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writer ️👏<strong>️️</strong></li><li>Follow us: <a href="https://x.com/inPlainEngHQ"><strong>X</strong></a> | <a href="https://www.linkedin.com/company/inplainenglish/"><strong>LinkedIn</strong></a> | <a href="https://www.youtube.com/@InPlainEnglish"><strong>YouTube</strong></a> | <a href="https://newsletter.plainenglish.io/"><strong>Newsletter</strong></a> | <a href="https://open.spotify.com/show/7qxylRWKhvZwMz2WuEoua0"><strong>Podcast</strong></a> | <a href="https://differ.blog/inplainenglish"><strong>Differ</strong></a> | <a href="https://twitch.tv/inplainenglish"><strong>Twitch</strong></a></li><li><a href="https://differ.blog/"><strong>Start your own free AI-powered blog on Differ</strong></a> 🚀</li><li><a href="https://discord.gg/in-plain-english-709094664682340443"><strong>Join our content creators community on Discord</strong></a> 🧑🏻‍💻</li><li>For more content, visit <a href="https://plainenglish.io/"><strong>plainenglish.io</strong></a> + <a href="https://stackademic.com/"><strong>stackademic.com</strong></a></li></ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=ea2232e8ce2b" width="1" height="1" alt=""><hr><p><a href="https://blog.venturemagazine.net/zen-out-the-ai-news-ea2232e8ce2b">Zen out the AI news.</a> was originally published in <a href="https://blog.venturemagazine.net">Venture</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        
    </channel>
</rss>