<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/">
    <channel>
        <title>Frank Cozzolino - Blog &amp; Insights</title>
        <link>https://frankcozzolino.github.io/</link>
        <description>Thoughts, ideas, and professional insights on technology, project management, and professional development</description>
        <language>en-us</language>
        <lastBuildDate>Fri, 18 Jul 2025 08:20:43 GMT</lastBuildDate>
        <ttl>60</ttl>
        <image>
            <url>https://frankcozzolino.github.io/images/signature.png</url>
            <title>Frank Cozzolino</title>
            <link>https://frankcozzolino.github.io/</link>
        </image>
        
        <item>
            <title>â€œAI isnâ€™t delivering valueâ€ and â€œWhy Firing People for AI Agents is a Costly Mistakeâ€â€Šâ€”â€Š40% ofâ€¦</title>
            <link>https://frankcozzolino.github.io/blog.html?article=ai-isnt-delivering-value-and-why-firing-people-for</link>
            <guid>https://frankcozzolino.github.io/blog.html?article=ai-isnt-delivering-value-and-why-firing-people-for</guid>
            <pubDate>Thu, 17 Jul 2025 08:20:20 GMT</pubDate>
            <dc:creator>Francesco C.</dc:creator>
            <category>budget</category>
            <category>product-management</category>
            <category>business-strategy</category>
            <category>corporate-culture</category>
            <category>ai</category>
            <description>â€œAI isnâ€™t delivering valueâ€ and â€œWhy Firing People for AI Agents is a Costly Mistakeâ€ â€” 40% of Agentic AI projects will fail.when strategy, measurement, and execution are weak and over 40% of Agentic...</description>
            <enclosure url="https://cdn-images-1.medium.com/max/1024/1*-XloYdAw_hSW_izDAL06_Q.png" type="image/jpeg" length="0"/>
            <content:encoded><![CDATA[<h3>â€œAI isnâ€™t delivering valueâ€ and â€œWhy Firing People for AI Agents is a Costly Mistakeâ€â€Šâ€”â€Š40% of Agentic AI projects willÂ fail.</h3><blockquote>when strategy, measurement, and execution are weak and over 40% of Agentic AI projects will fail by the end of 2027 due to cost hikes, murky ROI, and integration issues.</blockquote><blockquote>68% of companies are spending $50M to $250M annually on GenAIâ€Šâ€”â€Šonly 31% expect to measure ROI within sixÂ months</blockquote><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*-XloYdAw_hSW_izDAL06_Q.png" /></figure><p><strong>Introduction</strong></p><p>Enterprises worldwide are embracing generative AI (GenAI) with unmatched enthusiasm. Yet behind the optimism lies a cautionary tale: <strong>rushing into AI adoption without strategic planning, financial oversight, and a clear purpose can lead to budget overruns, failed projects, and a hollow return on investment (ROI).</strong> Perhaps most dangerously, some firms are laying off staff prematurely, betting on AI agents to replace human capital. But as the evidence shows, <strong>this short-sighted strategy often leads to higher costs, compliance risks, and operational inefficiencies.</strong></p><p><strong>1. Ballooning Budgets and UnseenÂ Costs</strong></p><p>Gartner forecasts GenAI-related spending to top <strong>$644 billion in 2025</strong>, with many enterprises surprised by costs not accounted for upfront. As seen in Thermo Fisher Scientificâ€™s chatbot pilot, consumption-based pricing quickly spiraled out of control. What began as a promising automation initiative nearly collapsed due to unpredictable data usage fees and model hallucinations that posed compliance issues (<a href="https://www.computerworld.com/article/4021954/rushing-into-genai-prepare-for-budget-blowouts-and-broken-promises.html">Computerworld</a>).</p><p>Capgemini CEO Aiman Ezzat highlighted another failure: an internal chatbot was projected to cost <strong>$25 million annually</strong> in data processingâ€Šâ€”â€Šforcing its termination before launch. The lesson: GenAI tools often <strong>require more compute, integration, and oversight</strong> than anticipated, and costs compound rapidly withÂ scale.</p><p>According to Gartner, custom GenAI models can cost <strong>$5â€“20 million to build</strong>, plus <strong>$8,000â€“21,000 per user per year</strong>, with API usage adding hundreds of thousands more. These expenses often surprise companies who budget only for initial implementation.</p><p><strong>2. ROI RemainsÂ Elusive</strong></p><p>Despite massive investmentsâ€Šâ€”â€Š<strong>68% of companies are spending $50M to $250M annually</strong> on GenAIâ€Šâ€”â€Šonly <strong>31% expect to measure ROI within six months</strong> (<a href="https://www.cio.com/article/3778320/enterprises-willing-to-spend-up-to-250-million-on-gen-ai-but-roi-remains-elusive.html">CIO.com</a>). Organizations fail to align AI projects with core KPIs, and many ignore foundational needs like data governance, model explainability, and human oversight.</p><p>Even in analytics, where AI and automation should shine, companies struggle to quantify value. A TechRadar report found success only when IT leaders define metrics upfront, invest in training, and connect automation outcomes with businessÂ goals.</p><p>A McKinsey/CIO study confirms that just <strong>31% anticipate measurable value shortly</strong>, citing data, governance, and alignment as consistent lags. The lesson is clear: without discipline and alignment, even generous GenAI budgets fail toÂ deliver.</p><p><strong>3. Project Failures and the AI HypeÂ Hangover</strong></p><p>Gartner analysts say GenAI is moving past its â€œpeak hypeâ€ into the <strong>â€œtrough of disillusionment.â€</strong> Many deployments in 2024 were scrapped due to unclear value or misaligned expectations (<a href="https://www.itpro.com/business/business-strategy/generative-ai-enthusiasm-continues-to-beat-out-business-uncertainty">ITPro</a>). Nearly <strong>42% of AI initiatives</strong> fail before reaching production.</p><p>Reasons include:</p><ul><li>Poor integration with legacyÂ systems</li><li>Inaccurate or low-quality data</li><li>Ethical/legal blindÂ spots</li><li>Lack of cross-functional leadership</li></ul><p>These pitfalls are exacerbated when firms remove experienced staff who would otherwise provide the institutional knowledge and governance required forÂ success.</p><p>The Economist reports that abandonment of AI pilots leapt from 17% to <strong>42%</strong> in one year, with some companies rehiring staff to fix flawed systems. Anthropicâ€™s vending machine AI failed in live trialsâ€Šâ€”â€Šmispricing goods and generating nonsenseâ€Šâ€”â€Šproving that human-in-the-loop oversight is not optional.</p><p><strong>4. The Human Cost: Layoffs and False Economies</strong></p><p>Many companies now equate productivity with profitability and mistakenly see GenAI as a labor cost-cutting tool. But firing employees to replace them with AI agents creates <strong>false economies.</strong></p><p>AI agents stillÂ require:</p><ul><li>Manual validation and oversight</li><li>Regular prompt engineering andÂ tuning</li><li>Ongoing retraining on updatedÂ datasets</li></ul><p>Scale AI laid off 14% of its workforce after its GenAI pods grew too expensive and underperformed. Klarna replaced 700 service jobs with AI but quickly reversed course when quality and satisfaction dropped.</p><p>As Capgeminiâ€™s CEO warned, <strong>productivity doesnâ€™t equal savings</strong>, especially in lower-wage roles. And as RHR Internationalâ€™s CIO noted, successful projects budget for human governance and experimentationâ€Šâ€”â€Šfactors impossible to replace entirely withÂ AI.</p><p>A Stanford study found that hybrid human-AI teams are <strong>14% more productive</strong> and deliver higher satisfaction than either alone. AI deployment without integrated human roles leads to chaos, not efficiency.</p><p><strong>Conclusion: Invest in AI <em>with</em> People, Not <em>instead</em> ofÂ Them</strong></p><p>Generative AI holds enormous potential. But chasing savings by cutting headcount and offloading critical roles to AI agents is a misstep that will likely cost companies more in the long runâ€Šâ€”â€Šthrough failed projects, regulatory risks, and lostÂ trust.</p><p><strong>AI should augment, not replace, your workforce.</strong></p><p>The future belongs to those who pair machine intelligence with human judgmentâ€Šâ€”â€Šstrategically, ethically, and with financial clarity. Companies that rush blindly forward will pay twice: once in money, and again in lost opportunity.</p><h3>Thank you for being a part of the community</h3><p><em>Before youÂ go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writerÂ ï¸ğŸ‘<strong>ï¸ï¸</strong></li><li>Follow us: <a href="https://x.com/inPlainEngHQ"><strong>X</strong></a> | <a href="https://www.linkedin.com/company/inplainenglish/"><strong>LinkedIn</strong></a> | <a href="https://www.youtube.com/@InPlainEnglish"><strong>YouTube</strong></a> | <a href="https://newsletter.plainenglish.io/"><strong>Newsletter</strong></a> | <a href="https://open.spotify.com/show/7qxylRWKhvZwMz2WuEoua0"><strong>Podcast</strong></a> |Â <a href="https://twitch.tv/inplainenglish"><strong>Twitch</strong></a></li><li><a href="https://differ.blog/"><strong>Start your own free AI-powered blog on Differ</strong></a>Â ğŸš€</li><li><a href="https://discord.gg/in-plain-english-709094664682340443"><strong>Join our content creators community on Discord</strong></a>Â ğŸ§‘ğŸ»â€ğŸ’»</li><li>For more content, visit <a href="https://plainenglish.io/"><strong>plainenglish.io</strong></a> + <a href="https://stackademic.com/"><strong>stackademic.com</strong></a></li></ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=03b77684a261" width="1" height="1" alt=""><hr><p><a href="https://blog.venturemagazine.net/ai-isnt-delivering-value-and-why-firing-people-for-ai-agents-is-a-costly-mistake-40-of-03b77684a261">â€œAI isnâ€™t delivering valueâ€ and â€œWhy Firing People for AI Agents is a Costly Mistakeâ€â€Šâ€”â€Š40% ofâ€¦</a> was originally published in <a href="https://blog.venturemagazine.net">Venture</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        
        <item>
            <title>I am Sorry, but We will never talk to ET</title>
            <link>https://frankcozzolino.github.io/blog.html?article=i-am-sorry-but-we-will-never-talk-to-et</link>
            <guid>https://frankcozzolino.github.io/blog.html?article=i-am-sorry-but-we-will-never-talk-to-et</guid>
            <pubDate>Thu, 26 Jun 2025 15:35:01 GMT</pubDate>
            <dc:creator>Francesco C.</dc:creator>
            <category>astronomy</category>
            <category>astrophysics</category>
            <category>ufology</category>
            <category>ufo</category>
            <category>ufos-and-aliens</category>
            <description>The life in the universe might not be rare, but definitely rarer than what we expected.The Drake equation has a lot of guessing, but even in our Solar system and nearby stars we tend to be alone....</description>
            <enclosure url="https://cdn-images-1.medium.com/max/1024/1*59rASJy1onpWv2dsBBhPrA.png" type="image/jpeg" length="0"/>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*59rASJy1onpWv2dsBBhPrA.png" /></figure><p>The life in the universe might not be rare, but definitely rarer than what we expected.</p><p>The Drake equation has a lot of guessing, but even in our Solar system and nearby stars we tend to be alone. Even microbes which should be everywhere seems to not be present anywhere in our Solar System (so far), which should be a good indicator that even the parameters below might be not very conservatives.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/928/1*ZBKoQsog-Lmakh3Stc0mWQ.png" /></figure><p>50000 species in the entire universe, since the beginning. Seems extremely small amount, and it is frightening to think about the implication of thatÂ number.</p><p>Nonetheless, we have another obstacle, thatâ€™s the great filter, and our technological revolution is extremely young. Moreover, we arrived very late to the party. Most of species could be already be extincted billions of yearsÂ ago.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/791/1*hzTXCYTx9gwrDiymxCSl4Q.png" /><figcaption>We ourselves appear at <strong>13.8 Gyr â†’ in the â€œLateâ€ epoch</strong>, near the trailing edge of cosmic habitability.</figcaption></figure><p>So, accounting for this the probability that we detect any other specie is basically 0.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/810/1*rzw6RsPsGo_s4nf38zXTAQ.png" /><figcaption>table showing, for each scenario, the expected number of detectable civilizations within our 100 ly listening volume and the corresponding probability (assuming a Poisson process, so P(â‰¥1)â‰ˆNdetectP(\ge1)\approx N_{\rm detect}P(â‰¥1)â‰ˆNdetectâ€‹ for Ndetectâ‰ª1N_{\rm detect}\ll1Ndetectâ€‹â‰ª1):</figcaption></figure><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=358236cdb664" width="1" height="1" alt="">]]></content:encoded>
        </item>
        
        <item>
            <title>Little-known Google Auth Feature that allows you to exchange PingFederate Token with Google Accessâ€¦</title>
            <link>https://frankcozzolino.github.io/blog.html?article=littleknown-google-auth-feature-that-allows-you-to</link>
            <guid>https://frankcozzolino.github.io/blog.html?article=littleknown-google-auth-feature-that-allows-you-to</guid>
            <pubDate>Thu, 26 Jun 2025 08:23:16 GMT</pubDate>
            <dc:creator>Francesco C.</dc:creator>
            <category>google</category>
            <category>token</category>
            <category>authorization</category>
            <category>pingfederate</category>
            <category>google-cloud-platform</category>
            <description>Little-known Google Auth Feature that allows you to exchange PingFederate Token with Google Access TokenğŸ« The Golden Ticket (Authorization Code)As a golden ticket in the OAuth 2.0 flow, the...</description>
            <enclosure url="https://cdn-images-1.medium.com/max/1024/0*Ii2CrjYQfJw0L0Ud" type="image/jpeg" length="0"/>
            <content:encoded><![CDATA[<h3>Little-known Google Auth Feature that allows you to exchange PingFederate Token with Google AccessÂ Token</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*Ii2CrjYQfJw0L0Ud" /></figure><h3>ğŸ« The Golden Ticket (Authorization Code)</h3><p>As a golden ticket in the OAuth 2.0 flow, the authorization code is a precious, short-lived credential representing proof of user consent. Issued by Googleâ€™s authorization server once a user authenticates and grants your application the requested scopes, this single-use code is an 80â€Šâ€”â€Š120-character, Base64-encoded string (e.g., â€œ4/0AVG7fiQ7Gâ€¦â€) that is bound to your appâ€™s client_id and the exact redirect_uri used in the initial request. Though it travels through potentially insecure channels like browser URL parameters, it remains useless to any attacker because it can only be redeemed at Googleâ€™s token endpoint in exchange for access and refresh tokens when presented alongside your client_secret. With a strict expiration window of about ten minutes and built-in cryptographic safeguards, the authorization code can safely bridge user consent to long-term API credentials without exposing your appâ€™sÂ secrets.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*2EFok-VbgwEMEOlL" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*pv0Pkf4KyTmcBmC5" /></figure><h3>Example</h3><pre>const tokenResponse = await fetch(&#39;https://oauth2.googleapis.com/token&#39;, {<br>    method: &#39;POST&#39;,<br>    headers: { &#39;Content-Type&#39;: &#39;application/x-www-form-urlencoded&#39; },<br>    body: new URLSearchParams({<br>      code,<br>      client_id: process.env.GOOGLE_CLIENT_ID || &#39;&#39;,<br>      client_secret: process.env.GOOGLE_CLIENT_SECRET || &#39;&#39;,<br>      redirect_uri: process.env.GOOGLE_REDIRECT_URI || &#39;&#39;,<br>      grant_type: &#39;authorization_code&#39;,<br>    }),<br>  });</pre><h3>References</h3><p><a href="https://developers.google.com/identity/protocols/oauth2">https://developers.google.com/identity/protocols/oauth2</a></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=679573ade04f" width="1" height="1" alt="">]]></content:encoded>
        </item>
        
        <item>
            <title>The WWW is almost dead, what next?</title>
            <link>https://frankcozzolino.github.io/blog.html?article=the-www-is-almost-dead-what-next</link>
            <guid>https://frankcozzolino.github.io/blog.html?article=the-www-is-almost-dead-what-next</guid>
            <pubDate>Wed, 25 Jun 2025 09:19:23 GMT</pubDate>
            <dc:creator>Francesco C.</dc:creator>
            <category>democracy</category>
            <category>ai</category>
            <category>humanity</category>
            <category>social-media</category>
            <category>internet</category>
            <description>From the gritty garages of Silicon Valley to the neon lit high rises of Manhattan, the World Wide Web burst onto the scene in 1991 as Tim Berners Leeâ€™s brainchild at CERN. What started as a simple...</description>
            <enclosure url="https://cdn-images-1.medium.com/max/1024/1*fkaVio8nZNIIybBB6Xzmeg.png" type="image/jpeg" length="0"/>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*fkaVio8nZNIIybBB6Xzmeg.png" /></figure><p>From the gritty garages of Silicon Valley to the neon lit high rises of Manhattan, the World Wide Web burst onto the scene in 1991 as Tim Berners Leeâ€™s brainchild at CERN. What started as a simple network of hyperlinked documents quickly morphed into a digital coliseum, with browsers duking it out on desktop stages and dot com fortunes rising and crashing faster than a subway express. By the turn of the millennium, the Web had rewired everything newsstands, corner bodegas, Wall Street tickers turning every New Yorker into a pixel in the globalÂ grid.</p><p>In the 1990s, the Internet kicked off as a noisy neon bazaar: dialâ€‘up modems chirped in suburban bedrooms while Netscape Navigator ruled the streets, and Geocities homepages bloomed like wild graffiti. Bulletin boards and IRC channels became the cool underground clubs where chat room denizens swapped ASCII art and MP3s on Napster lit the fire for digital file sharing. By the turn of the millennium, the dotâ€‘com boom turned startups into overnight Wall Street darlings pets.com and pets spelled out the risks of unbridled hype when the bubble burst in 2000.<br>The early 2000s reloaded the Web into Version 2.0: blogs sprouted like newsstands on every corner, MySpaceâ€™s rocker profiles and Friendsterâ€™s exclusive clubs set the template, and eâ€‘commerce giants like Amazon and eBay turned oneâ€‘click buying into a citywide habit. Streaming video and podcasts began rumbling beneath the surface, while broadband quietly replaced dialâ€‘up, ushering in faster scrolls and richer media. This era proved that between the dialâ€‘up thunks and the postâ€‘bubble revelations, the Internet wasnâ€™t just a passing fad but a gritty, evolving metropolis one built on community, commerce, and the code to keep hustling.</p><p>Enter the AI era, the World Wide Web, once a sprawling agora of shared ideas and unbridled curiosity, lies comatose. In its place stands an ironclad ecosystem of â€œknowledgeâ€ meticulously distilled into soulless shards by faceless corporations and opaque government bureaus. Welcome to our new digital age: a sterile, privatized vault where every byte of information is bartered, fenced off, and rationed to suit the whims of remote dataÂ barons.</p><p>Digital isolation has become the default. No longer do communities gather in bustling chatrooms or exchange ideas freely across blogs. Instead, individuals retreat into algorithmically sanctioned bubbles small, well lit cages that hum with the comforting glow of curated content. Donâ€™t bother wandering beyond the paywalls and firewalls; youâ€™ll find nothing but echoes of your own preferences, an intoxicating loop designed to keep you clicking and consuming until the model dictates otherwise.<br>Knowledge fenced gardens are flourishing. Major tech conglomerates now host â€œpremiumâ€ archives of the human record, available only via subscription tiers that rival luxury car leases. Want to read the complete works of Shakespeare? Thatâ€™ll be â‚¬19.99 a month, please. Need the latest climate data? First you must verify your identity and prove youâ€™ve purchased the â€œEnterprise Insightsâ€ package. These walled off libraries masquerade as convenience, but the truth is blatant: profit has trumped public good, and weâ€™re left paying tribute to invisible gatekeepers.<br>Privatization of knowledge isnâ€™t subtle. Governments, under the guise of â€œnational security,â€ have signed lucrative licensing deals with private model providers, effectively offloading public archives into corporate vaults. What was once funded by tax dollars is now repackaged as exclusive â€œinsightsâ€ for a privileged few. Even academic research once a bastion of open peer review has been siphoned into restricted APIs that throttle access unless you hold the right credentials or creditÂ card.</p><p>The social fabric has frayed. We are less social, more alone in our digital cocoons. Physical proximity no longer guarantees authenticity; nor does online proximity. Your next door neighbor might be a manufactured persona in a mass produced chat interface. Friends you thought you knew on Discord could just as easily be bots, churning out canned sympathies in response to your darkest confessions. Emotional labor is outsourced to simulacra, making genuine human connection a relic of a bygone era.<br>Once the go to hunting grounds for late night confidences and pixel perfect romances chatrooms, forums and dating apps now reek of synthetic sincerity. You pour your heart out over text or even video, only to realize the â€œpersonâ€ on the other end might be nothing more than a neural puppet. Those laugh track jokes, the perfectly timed empathies, the coy good morning selfies theyâ€™re all expertly generated by black box models designed to keep you hooked. You canâ€™t swipe right on authenticity when every profile could be a cleverly animated faÃ§ade, every â€œI miss youâ€ a line of code, and every â€œletâ€™s video chatâ€ a deepfake waiting to expose your most private moments to corporate auditors. And hereâ€™s the clincher: you never know whether youâ€™re talking to a human or a neural network. Every article, every comment, every â€œliveâ€ video stream is suspect. Content could be fabricated from scratch by generative models that have ingested our collective culture and spat it back out, polished to a deceptive shine. Skepticism is the only currency left yet skepticism itself has been commodified into â€œfact checkingâ€ services that charge perÂ claim.</p><p>So, farewell to the democratized dream of the early internet. The web is dead, and all hail the new overlords ofÂ data.</p><p>To be continuedÂ â€¦</p><h3>Thank you for being a part of the community</h3><p><em>Before youÂ go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writerÂ ï¸ğŸ‘<strong>ï¸ï¸</strong></li><li>Follow us: <a href="https://x.com/inPlainEngHQ"><strong>X</strong></a> | <a href="https://www.linkedin.com/company/inplainenglish/"><strong>LinkedIn</strong></a> | <a href="https://www.youtube.com/@InPlainEnglish"><strong>YouTube</strong></a> | <a href="https://newsletter.plainenglish.io/"><strong>Newsletter</strong></a> | <a href="https://open.spotify.com/show/7qxylRWKhvZwMz2WuEoua0"><strong>Podcast</strong></a> |Â <a href="https://twitch.tv/inplainenglish"><strong>Twitch</strong></a></li><li><a href="https://differ.blog/"><strong>Start your own free AI-powered blog on Differ</strong></a>Â ğŸš€</li><li><a href="https://discord.gg/in-plain-english-709094664682340443"><strong>Join our content creators community on Discord</strong></a>Â ğŸ§‘ğŸ»â€ğŸ’»</li><li>For more content, visit <a href="https://plainenglish.io/"><strong>plainenglish.io</strong></a> + <a href="https://stackademic.com/"><strong>stackademic.com</strong></a></li></ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=a1199883f200" width="1" height="1" alt=""><hr><p><a href="https://blog.stackademic.com/the-www-is-almost-dead-what-next-a1199883f200">The WWW is almost dead, what next?</a> was originally published in <a href="https://blog.stackademic.com">Stackademic</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        
        <item>
            <title>Vibe Coding 2/5 â€”From Vibe coding to UML Coding.</title>
            <link>https://frankcozzolino.github.io/blog.html?article=vibe-coding-25-from-vibe-coding-to-uml-coding</link>
            <guid>https://frankcozzolino.github.io/blog.html?article=vibe-coding-25-from-vibe-coding-to-uml-coding</guid>
            <pubDate>Mon, 23 Jun 2025 07:50:06 GMT</pubDate>
            <dc:creator>Francesco C.</dc:creator>
            <category>cursor-ai</category>
            <category>vibe-coding</category>
            <category>cursor</category>
            <category>uml-diagrams</category>
            <category>ai-coding</category>
            <description>â€œVibe coding is fun, but it lacks professionalism and causes many people to burn out due to bad results. Luckily, CS classes have taught UML design for pretty much forever. Almost no vibe coders...</description>
            <enclosure url="https://cdn-images-1.medium.com/max/1024/1*pcUG-skiFHVpVHCPO1lbRg.png" type="image/jpeg" length="0"/>
            <content:encoded><![CDATA[<p>â€œVibe coding is fun, but it lacks professionalism and causes many people to burn out due to bad results. Luckily, CS classes have taught UML design for pretty much forever. Almost no vibe coders today use UML; most merely â€œtype with the model.â€ No wonder they feel theÂ drain.â€</p><p>Read â€œVibe Coding 2/5â€Šâ€”â€ŠFrom Vibe coding to UML Coding â€œ by Francesco C. on Medium: <a href="https://medium.com/@francesco.cozzolino/vibe-coding-2-5-from-vibe-coding-to-uml-coding-711e5510de29">https://medium.com/@francesco.cozzolino/vibe-coding-2-5-from-vibe-coding-to-uml-coding-711e5510de29</a></p><h3>The book</h3><p>I strongly advice everyone to purchase this book and absorb everything said. This book pretty much changed my life and made me better, showed me the way, this goes beyond programming, this methodology you can apply to any Big Problem you will face in theÂ life.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*pcUG-skiFHVpVHCPO1lbRg.png" /></figure><h3>The Shift from Coders to Architects</h3><p>Think of it as an evolution, not a replacement. The arrival of AI in software development isnâ€™t about eliminating our rolesâ€Šâ€”â€Šitâ€™s about transforming them. Instead of spending 99% of our time typing lines of code, weâ€™ll shift our focusÂ toward:</p><ul><li><strong>Architectural designÂ (UML)</strong></li><li><strong>Security protocols</strong></li><li><strong>AI strategy and governance</strong></li></ul><p>In effect, we become <strong>project architects by default</strong>. Our deep knowledge of design patterns, threat modeling, and system diagrams becomes the currency of innovation, while AI handles the boilerplate.</p><h3>The Big-Picture Imperative</h3><p>Itâ€™s like when hunter-gatherers first turned to agriculture. They no longer spent every waking moment foraging; they could build sturdier homes, sharpen better tools, and cultivate culture. If our goal is to conquer the galaxy, we canâ€™t do it one line of code at a time. We need to understand the architecture of the universeÂ itself.</p><p>AI liberates us from the minutiae: the endless debugging, the repetitive refactoring, the routine unit tests. Instead, we ask bigger questions:</p><ul><li>How do we secure quantum-resistant communication?</li><li>What standards govern AI ethics across interplanetary networks?</li><li>How can we design self-healing architectures that adapt in realÂ time?</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*nGx1xUK18QbaGlw0-k_Jrw.png" /></figure><h3>What isÂ UML?</h3><p>UML Unified Modeling Language (UML) is a powerful, standardized modeling language that emerged from the field of software engineering, primarily designed to specify, visualize, construct, and document software systems. Developed in the 1990s by industry leaders Grady Booch, James Rumbaugh, and Ivar Jacobson, UML became a critical tool for software developers, providing clarity and consistency in system design and facilitating effective communication among development teams. Its broad acceptance is due largely to its flexibility, scalability, and ability to manage complexity through visual abstraction and standardized notation. At its core, UML provides a structured visual language with multiple diagram types that address different aspects of system design and analysis. These diagram types include structural diagrams such as class diagrams and object diagrams, as well as behavioral diagrams including use-case diagrams, activity diagrams, and sequence diagrams. Each diagram type is tailored to effectively represent different perspectives of systemsâ€Šâ€”â€Šwhether static relationships, interactive behaviors, or dynamic sequences of operations. In the context of analyzing scientific papers, UMLâ€™s robust ability to represent complex interactions and logical sequences becomes particularly valuable. Sequence diagrams, one of UMLâ€™s behavioral diagram types, are especially suited to illustrating dynamic interactions and the temporal progression of events. They clearly depict how different entities or components communicate and interact over time, making them ideal for modeling logical arguments, evidence flows, and conclusions within academic literature.</p><h3>The main 3 diagrams you need toÂ master</h3><h3>Use CaseÂ Diagram</h3><p>Purpose: Captures functional requirements by showing the interactions between external actors (users or systems) and theÂ feature.</p><p>When to use: At the very start of feature design, to align stakeholders on what the feature must do and who will useÂ it.</p><h4>Key elements:</h4><p>Actors (stick figures): represent roles interacting with theÂ system</p><p>Use cases (ovals): represent specific user goals or functions</p><p>System boundary (rectangle): encapsulates the featureâ€™s scope</p><p>Associations (lines): connect actors to the use cases they participate in</p><p>Benefits: Clarifies scope, highlights user needs, uncovers missing requirements.</p><h3>Sequence Diagram</h3><p>Purpose: Models the dynamic interactions and message flows between objects/components overÂ time.</p><p>When to use: Once you know the key actors and use cases; to detail the step-by-step flow for a particular scenario or operation within theÂ feature.</p><h4>Key elements:</h4><p>Lifelines (vertical dashed lines): represent participant objects or components</p><p>Activation bars (thin rectangles on lifelines): indicate when an object isÂ active</p><p>Messages (horizontal arrows): show calls or data transfers, labeled with operation names</p><p>Return messages (dashed arrows): show responses or returnedÂ values</p><p>Benefits: Identifies required interfaces, clarifies sequencing and concurrency, surfaces timing or ordering issuesÂ early.</p><h3>Class Diagram</h3><p>Purpose: Defines the static structure of the feature by showing classes, their attributes, methods, and relationships.</p><p>When to use: After youâ€™ve specified interactions (via sequence diagrams) and know which objects must exist; to consolidate data structures and API contracts.</p><h4>Key elements:</h4><p>Classes (rectangles divided into three compartments): name, attributes, and operations</p><p>Associations (lines): depict relationships (e.g., one-to-many) betweenÂ classes</p><p>Inheritance/generalization (lines with hollow triangle): show parent/child hierarchies</p><p>Dependencies (dashed arrows): indicate usage without ownership</p><p>Benefits: Provides a clear blueprint for implementation, aids in code generation or manual coding, ensures a consistent objectÂ model.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=711e5510de29" width="1" height="1" alt="">]]></content:encoded>
        </item>
        
        <item>
            <title>Superintelligence Isnâ€™t Imminentâ€Šâ€”â€ŠAnd The Illusion of Thinking.</title>
            <link>https://frankcozzolino.github.io/blog.html?article=superintelligence-isnt-imminent-and-the-illusion-o</link>
            <guid>https://frankcozzolino.github.io/blog.html?article=superintelligence-isnt-imminent-and-the-illusion-o</guid>
            <pubDate>Tue, 17 Jun 2025 08:57:14 GMT</pubDate>
            <dc:creator>Francesco C.</dc:creator>
            <category>artificial-intelligence</category>
            <category>ai-research</category>
            <category>ai</category>
            <category>cognitive-science</category>
            <category>machine-learning</category>
            <description>ğŸ§  Superintelligence Isnâ€™t Imminent â€” And The Illusion of Thinking.Despite all the hype around superintelligent AI systems poised to surpass human capabilities, a fresh wave of research paints a very...</description>
            <enclosure url="https://cdn-images-1.medium.com/max/1024/1*ZshpwrA1mv_wEd7aAhvlgA.png" type="image/jpeg" length="0"/>
            <content:encoded><![CDATA[<h3>ğŸ§  Superintelligence Isnâ€™t Imminentâ€Šâ€”â€ŠAnd The Illusion of Thinking.</h3><p>Despite all the hype around superintelligent AI systems poised to surpass human capabilities, a fresh wave of research paints a very differentâ€Šâ€”â€Šand much more groundedâ€Šâ€”â€Špicture. Appleâ€™s recent study, <em>â€œThe Illusion of Thinkingâ€</em>, alongside contributions from leading researchers and media outlets, calls into question the narrative of imminent Artificial General Intelligence (AGI). What weâ€™re witnessing, it seems, isnâ€™t the rise of a digital Einsteinâ€Šâ€”â€Šbut something more brittle, narrow, and surprisingly easy toÂ fool.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*ZshpwrA1mv_wEd7aAhvlgA.png" /></figure><h3>1. Recent Findings Challenge theÂ Hype</h3><p>In <em>â€œThe Illusion of Thinkingâ€</em>, Apple tested leading large language models (LLMs) from OpenAI, Anthropic, and Google on classic reasoning puzzles like Tower of Hanoi and River Crossing. The results were startling: the models, often perceived as near-omniscient, failed logic problems solvable by school children. Worse, as task complexity increased, their ability to complete the problems dropped sharplyâ€Šâ€”â€Šsometimes they even stopped trying mid-task.</p><h4>Recent Findings Challenge the AIÂ Hype</h4><p>Appleâ€™s new 2025 study <em>â€œThe Illusion of Thinkingâ€</em> put leading chain-of-thought LLMs to the test with classic logic puzzles. The team evaluated models from OpenAI (o3), Anthropic (Claude 3.7), and Google (Gemini) on tasks like Tower of Hanoi, a river-crossing problem, checkers jumping, and block-stacking. These puzzles were scaled from trivial (e.g. 1-disk Hanoi) to extremely hard (e.g. 20-disk Hanoi requiring over a million moves). In practice, these are problems a schoolchild can solve by following simple rules, so any AI failure is unexpected. Indeed, the AI models <strong>performed poorly even on moderate puzzles</strong>: for example, they â€œconsistently failed at Tower of Hanoi,â€ scoring under 80% on a 7-disk puzzle and essentially 0% at 8 disks. Similar breakdowns occurred on the river-crossing and block-stacking puzzles, revealing that these high-profile LLMs could not handle basic logical reasoning.</p><h4>Key Findings</h4><ul><li><strong>Complexity regimes:</strong> The Apple paper identifies three regimes. On very easy tasks, <em>standard</em> LLMs (no extra â€œchain-of-thoughtâ€) actually outperformed the chain-of-thought LRMs; on moderately hard tasks, the LRMs had an edge; on very hard tasks, <em>all</em> models collapsed.</li><li><strong>Complete collapse:</strong> The authors observe a â€œcomplete accuracy collapse beyond certain complexitiesâ€. In other words, once puzzle size passes a threshold, none of the models solved it correctly.</li><li><strong>Specific failures:</strong> In concrete terms, the LLMs <em>â€œconsistently failedâ€</em> the test puzzles. For example, accuracy plunged below 80% on a 7-disk Tower of Hanoi and to ~0% at 8 disks. They also failed the Blocks World and river-crossing puzzles with the same ease as flipping heads on aÂ coin.</li><li><strong>Solution truncation:</strong> The models often stopped mid-solution once answers got long. In practice, a model might begin listing the moves and then insert â€œIâ€™ll stop hereâ€ when the token budget is reached. (Critics note these token limits can mimic a â€œcollapse.â€)</li><li><strong>No explicit algorithms:</strong> Apple found that LRMs â€œfail to use explicit algorithms and reason inconsistently across puzzlesâ€. In short, the modelâ€™s internal â€œthinkingâ€ was erratic rather than systematic.</li></ul><p>These outcomes show that current LLMsâ€™ impressive chain-of-thought outputs can still break down under moderate complexity. Beyond a certain point, giving extra â€œthinking stepsâ€ does <em>not</em> make the models solve problems correctly. In fact, the study concludes that these reasoning models only work up to a limited complexity, after which their performance collapses catastrophically.</p><h4>Implications for AI Understanding</h4><p>Even when LLMs produce elaborate internal â€œreasoning,â€ that process may not be logical. Appleâ€™s co-author Iman Mirzadeh emphasizes that even when the model was <em>given</em> the correct solution algorithm, it â€œstill failedâ€ the puzzleâ€Šâ€”â€Šits process â€œis not logical and intelligentâ€. In other words, the step-by-step chain-of-thought it outputs can be misleading. As MacDailyNews reports, the study suggests these AI models simply â€œgenerate responses that align with pattern-matchingâ€ from their training data, rather than deducing new logic. This echoes Gary Marcusâ€™s point that neural nets can only â€œgeneralize within a distributionâ€ they have seen and â€œtend to break down beyond that distributionâ€. In short, <strong>highly polished AI answers are not proof of genuine understanding</strong>; the models may be drawing on learned patterns instead of applying true reasoning.</p><h4>Critiques and Counterpoints</h4><p>These surprising failures have prompted debate. Open Philanthropy researcher Alex Lawsen argues that the reported â€œcollapseâ€ often reflects evaluation choices, not just model limitations. For example, at the point Apple marked the 8-disk Hanoi as failed, the model was already bumping into its token limit (even printing â€œIâ€™ll stop hereâ€). Lawsen found that if you instead prompt the model to output a concise program (e.g. a recursive algorithm) rather than listing every move, the models easily solve much larger instances (15-disk Hanoi). He also notes Appleâ€™s river-crossing tests included impossible configurations (no solution), so a correct â€œno solutionâ€ answer was scored as a failure. These points suggest the AI was partly failing due to output-format constraints, not only reasoning deficits. Nonetheless, Lawsen agrees that current LLMs still lack robust, generalizable reasoning: truly proving algorithmic intelligence remains an open challenge. In any case, both the original study and its critiques highlight that how we test â€œreasoningâ€ matters. Future benchmarks must separate genuine logical skill from practical outputÂ limits.</p><p>In summary, the Apple puzzle experiments offer a reality check: even cutting-edge LLMs can falter on deceptively simple tasks, underscoring the gap between <em>appearance</em> and <em>understanding</em>. As Futurism puts it, these models â€œare no substitute for good, well-specified algorithms,â€ and their impressive outputs should not be taken as evidence of true intelligence.</p><h3>2. Limits in Logic and Reasoning</h3><p>One key insight from Appleâ€™s research is that current LLMs rely heavily on <strong>pattern recognition</strong>, not true reasoning. They excel when regurgitating information that resembles their training data but falter when faced with novelty. As complexity rises or context shifts, their logical scaffolding crumbles.</p><p>This means we are still far from AIs that can <em>reason</em> through real-world problems in flexible, adaptiveÂ ways.</p><h3>3. Superintelligence Trust Outpaces Capabilities</h3><p>Tech leaders like Sam Altman (OpenAI), Demis Hassabis (Google DeepMind), and Dario Amodei (Anthropic) have publicly speculated about the nearness of AGI. But Appleâ€™s findingsâ€Šâ€”â€Šand corroborating critiquesâ€Šâ€”â€Šsuggest that these forecasts are <strong>leaps ahead of actual performance</strong>.</p><p>While marketing claims lean toward inevitability, the modelsâ€™ analytical capabilities lag significantly behind expectations. Trust in â€œsuperintelligenceâ€ is growing faster than the techâ€™s actual reasoning abilities.</p><h3>4. Emergent Tasks â‰  General Reasoning</h3><p>Some AI advocates point to â€œemergent behaviorâ€ as evidence of intelligenceâ€Šâ€”â€Štasks the model seems to solve despite no direct training. Yet, <strong>emergence doesnâ€™t equal generality</strong>.</p><p>These systems often display narrow brilliance that doesnâ€™t transfer outside very specific formats. Being good at solving math benchmarks or chess problems doesnâ€™t mean the model can reason abstractly or solve unfamiliar, open-ended questions.</p><h3>5. Memory Without Comprehension</h3><p>These models are <strong>masters of mimicry</strong>, not meaning. They recall and remix text without true comprehensionâ€Šâ€”â€Šan issue compared by some researchers to a â€œstochastic parrot.â€ They can ace standardized tests by parroting patterns but lack conceptual frameworks.</p><p>This leads to superficial results: a model that can draft a research summary or pass a quiz may not â€œunderstandâ€ anything itÂ says.</p><h3>6. Pattern vs. Reason: Hybrid Intelligence Is a SmarterÂ Goal</h3><p>Emerging academic consensus suggests that scaling current models may <strong>not</strong> bring us closer to genuine intelligence. Instead, <strong>hybrid intelligence</strong>â€Šâ€”â€Šsystems combining AIâ€™s computational power with human intuition and conceptual reasoningâ€Šâ€”â€Šmay be the more realistic and safe trajectory.</p><p>Rather than replacing humans, future systems could <strong>collaborate</strong> with us, complementing our strengths rather than mimicking our thinking.</p><h3>7. Superintelligence Raises Complex ControlÂ Problems</h3><p>The theoretical risks of superintelligent systemsâ€Šâ€”â€Šlike alignment failure and existential threatsâ€Šâ€”â€Šhave been explored by scholars like Nick Bostrom. But Appleâ€™s study reinforces that weâ€™re <strong>nowhere near that threshold</strong>.</p><p>We may one day face such control dilemmas, but right now, a bigger problem is the <strong>overconfidence in AIâ€™s current capabilities</strong>â€Šâ€”â€Ša misunderstanding that could lead to careless deployment or misplaced trust.</p><h3>8. Policy Implications DemandÂ Realism</h3><p>As governments rush to regulate AI, <strong>misjudging its capabilities could backfire</strong>. Overestimating what these systems can do may lead to inappropriate legal frameworks, poorly allocated funding, or even political fear-mongering.</p><p>Effective policy should be rooted in <strong>what AI actually is</strong>, not in sci-fi predictions. Appleâ€™s research urges a recalibration of the narrative.</p><h3>9. Household Tasks Donâ€™t Equal Awareness</h3><p>Writing a blog post, generating a spreadsheet formula, or replying to emails may seem intelligentâ€Šâ€”â€Šbut none of this requires <strong>awareness or understanding</strong>. Itâ€™s the <em>illusion</em> of thinking, not thinkingÂ itself.</p><p>Todayâ€™s systems appear useful not because they grasp meaning, but because theyâ€™ve digested billions of examples. Thatâ€™s not intelligenceâ€Šâ€”â€Šitâ€™s compression.</p><h3>10. Hype vs. Reality: Why ScrutinyÂ Matters</h3><p>Calling out AIâ€™s limitations isnâ€™t being cynicalâ€Šâ€”â€Š<strong>itâ€™s necessary</strong>. We canâ€™t build responsible systems if weâ€™re blinded by buzzwords. Appleâ€™s work is a reminder: <strong>understanding where we are helps ensure we go further, better, andÂ safer</strong>.</p><h3>Thank you for being a part of the community</h3><p><em>Before youÂ go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writerÂ ï¸ğŸ‘<strong>ï¸ï¸</strong></li><li>Follow us: <a href="https://x.com/inPlainEngHQ"><strong>X</strong></a> | <a href="https://www.linkedin.com/company/inplainenglish/"><strong>LinkedIn</strong></a> | <a href="https://www.youtube.com/@InPlainEnglish"><strong>YouTube</strong></a> | <a href="https://newsletter.plainenglish.io/"><strong>Newsletter</strong></a> | <a href="https://open.spotify.com/show/7qxylRWKhvZwMz2WuEoua0"><strong>Podcast</strong></a> |Â <a href="https://twitch.tv/inplainenglish"><strong>Twitch</strong></a></li><li><a href="https://differ.blog/"><strong>Start your own free AI-powered blog on Differ</strong></a>Â ğŸš€</li><li><a href="https://discord.gg/in-plain-english-709094664682340443"><strong>Join our content creators community on Discord</strong></a>Â ğŸ§‘ğŸ»â€ğŸ’»</li><li>For more content, visit <a href="https://plainenglish.io/"><strong>plainenglish.io</strong></a> + <a href="https://stackademic.com/"><strong>stackademic.com</strong></a></li></ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=69018636646e" width="1" height="1" alt=""><hr><p><a href="https://blog.stackademic.com/superintelligence-isnt-imminent-and-the-illusion-of-thinking-69018636646e">ğŸ§  Superintelligence Isnâ€™t Imminentâ€Šâ€”â€ŠAnd The Illusion of Thinking.</a> was originally published in <a href="https://blog.stackademic.com">Stackademic</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        
        <item>
            <title>Vibe Coding: A New Kind of Coding.â€Šâ€”â€ŠPart 1/5</title>
            <link>https://frankcozzolino.github.io/blog.html?article=vibe-coding-a-new-kind-of-coding-part-15</link>
            <guid>https://frankcozzolino.github.io/blog.html?article=vibe-coding-a-new-kind-of-coding-part-15</guid>
            <pubDate>Mon, 16 Jun 2025 10:26:53 GMT</pubDate>
            <dc:creator>Francesco C.</dc:creator>
            <category>ai-programming</category>
            <category>vibe-coding</category>
            <category>prompt-engineering</category>
            <category>ai-productivity</category>
            <category>llm-agent</category>
            <description>Vibe Coding: A New Kind of Coding. â€” Part 1/5Vibe coding is a high-level framework that abstracts the complexity of GPU and parallel programming, making CUDA kernels and thread management accessible...</description>
            <enclosure url="https://cdn-images-1.medium.com/max/1024/0*Yv2vRwl-OX80wLDA" type="image/jpeg" length="0"/>
            <content:encoded><![CDATA[<h3><strong>Vibe Coding: A New Kind of Coding.â€Šâ€”â€ŠPartÂ 1/5</strong></h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*Yv2vRwl-OX80wLDA" /></figure><blockquote>Vibe coding is a high-level framework that abstracts the complexity of GPU and parallel programming, making CUDA kernels and thread management accessible even to developers without deep specialized knowledge. By auto-optimizing memory transfers and kernel configurations, it delivers both higher performance and reduced energy consumption. Coupled with extensive UML-based design modeling, covering class, sequence, and deployment diagrams, teams can identify security risks early, enforce robust architectures, and minimize implementation flaws. Together, these approaches democratize high-performance computing, lower operational costs, and drive humanity toward faster, greener, and more secure software innovation.</blockquote><p>Thereâ€™s never much room for feeling in the cold logic of software engineering. Programs either run or they donâ€™t. Brackets match or they donâ€™t. The compiler doesnâ€™t care how inspired you felt at 2 a.m. But in 2025, a different kind of code is emergingâ€Šâ€”â€Šnot just from logic gates, but from architectural vision and natural language. Itâ€™s structured, holistic, and principled. And itâ€™s called vibeÂ coding.</p><p>While originally coined by Andrej Karpathy in a whimsical tweet, the term has since evolved far beyond its tongue-in-cheek roots. No longer shorthand for improvisational tinkering, vibe coding now represents a movement: a way of programming that empowers developers to zoom out and orchestrate systems, rather than wrestle endlessly with syntax andÂ bugs.</p><p>At its core, vibe coding is about clarity. It leverages AI not to bypass engineering, but to elevate it. By translating architectural plans into executable code, developers reclaim time lost in repetitive problem-solving. Instead of fixing broken imports or hunting for elusive null pointer exceptions, theyâ€™re spending that time crafting better user experiences, embedding resilience into their systems, and refining their securityÂ posture.</p><p>This is why UML diagrams and detailed technical design have become essential tools in vibe coding workflows. They serve as the blueprint from which all code generation is orchestrated. In the world of vibe coding, a well-structured technical plan isnâ€™t a nice-to-haveâ€Šâ€”â€Šitâ€™s the beating heart of the process. These visual schematics help align teams, inform prompts, and ensure consistency across modules, APIs, and data flows. The stronger the architecture, the more precise the AIâ€™s contribution.</p><p>It works through prompt-driven development. The developer writes natural language descriptions of the behavior or architecture they want. AI agentsâ€Šâ€”â€Šbe it Cursor, Copilot, Claude, or custom toolingâ€Šâ€”â€Šgenerate code that matches the spec. But the human role doesnâ€™t end there. Itâ€™s about guiding, auditing, and integrating that output with foresight and discipline. In short: vibe coding isnâ€™t hands-offâ€Šâ€”â€Šitâ€™s hands-on, but eyesÂ up.</p><p>Vibe coding redefines who the architect is. No longer does architectural thinking reside solely with senior engineers or system designers. With the right AI interfaces, even junior developers or domain experts can outline workflows, enforce constraints, and maintain system-wide integrity. This democratization of high-level design is changing the shape of teams and the nature of software planning.</p><p>Security is no afterthought in this world. One of Vibe Codingâ€™s greatest promises lies in its ability to embed secure defaults. Instead of retrofitting authorization rules or validating inputs after vulnerabilities are discovered, developers can encode policies into their prompts from the outset. â€œDesign the API to reject malformed JWT tokens,â€ one prompt might say. Or, â€œOnly allow data access if the userâ€™s session is active and within a specified role.â€ The AI generates these flows in real-time, weaving security into the applicationâ€™s fabric.</p><p>Critics still point fingers. They argue that AI-assisted development encourages laziness, or that it leads to black-box software, code nobody understands. But practitioners push back. They argue that the most responsible use of vibe coding is deeply intentional. The point isnâ€™t to abandon engineering; itâ€™s to sharpen it. To use AI to remove friction, notÂ thought.</p><p>â€œI used to spend days debugging cascading failures caused by brittle test setups,â€ says Gabriel Nassar, a software architect at a cybersecurity firm. â€œNow, I describe my resilience strategy up front, and the AI handles scaffolding. I still validate and test, but Iâ€™m not stuck in the weeds. Iâ€™m focused on the mission.â€</p><p>This shift is also freeing smaller teams to do more with less. By offloading time-consuming boilerplate tasks to AI, vibe coding gives developers more time to focus on rigorous testing. Small teams that once struggled to cover edge cases can now afford to build comprehensive test suites and validate their systems with greater confidence.</p><p>More importantly, vibe coding is helping redefine where engineering excellence can come from. In regions like Europe and the United States, where labor costs are higher and outsourcing has long been seen as a cost-saving necessity, vibe coding offers a new path. It allows local engineers to compete at scale, delivering sophisticated, high-integrity software systems without bloated headcounts or offshore labor. By automating the mundane, vibe coding lets domestic teams focus on quality, innovation, and architecture.</p><p>The tools themselves are maturing. AI models are learning to explain their logic, suggest tests, and integrate with CI/CD systems that enforce code health. Version-controlled prompt chainsâ€Šâ€”â€Šcomplete with architectural diagrams and security annotationsâ€Šâ€”â€Šare replacing scattered README files and spaghetti docstrings.</p><p>And perhaps most importantly, vibe coding is cultivating a new programming literacy. One that prizes systems thinking over brute force. One that empowers teams to move faster, not by skipping steps, but by making every step more intelligent.</p><p>The future wonâ€™t be built by AI alone. But it may be shaped by those who know how to harness itâ€”not recklessly, but withÂ intent.</p><p>Thatâ€™s the realÂ vibe.</p><h3>Thank you for being a part of the community</h3><p><em>Before youÂ go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writerÂ ï¸ğŸ‘<strong>ï¸ï¸</strong></li><li>Follow us: <a href="https://x.com/inPlainEngHQ"><strong>X</strong></a> | <a href="https://www.linkedin.com/company/inplainenglish/"><strong>LinkedIn</strong></a> | <a href="https://www.youtube.com/@InPlainEnglish"><strong>YouTube</strong></a> | <a href="https://newsletter.plainenglish.io/"><strong>Newsletter</strong></a> | <a href="https://open.spotify.com/show/7qxylRWKhvZwMz2WuEoua0"><strong>Podcast</strong></a> |Â <a href="https://twitch.tv/inplainenglish"><strong>Twitch</strong></a></li><li><a href="https://differ.blog/"><strong>Start your own free AI-powered blog on Differ</strong></a>Â ğŸš€</li><li><a href="https://discord.gg/in-plain-english-709094664682340443"><strong>Join our content creators community on Discord</strong></a>Â ğŸ§‘ğŸ»â€ğŸ’»</li><li>For more content, visit <a href="https://plainenglish.io/"><strong>plainenglish.io</strong></a> + <a href="https://stackademic.com/"><strong>stackademic.com</strong></a></li></ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=983bc651fbd7" width="1" height="1" alt=""><hr><p><a href="https://blog.stackademic.com/vibe-coding-a-new-kind-of-coding-part-1-5-983bc651fbd7">Vibe Coding: A New Kind of Coding.â€Šâ€”â€ŠPart 1/5</a> was originally published in <a href="https://blog.stackademic.com">Stackademic</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        
        <item>
            <title>OpenAIâ€™s o3-Pro Outranks PhDsâ€Šâ€”â€ŠNow the Experts Are Worried</title>
            <link>https://frankcozzolino.github.io/blog.html?article=openais-o3pro-outranks-phds-now-the-experts-are-wo</link>
            <guid>https://frankcozzolino.github.io/blog.html?article=openais-o3pro-outranks-phds-now-the-experts-are-wo</guid>
            <pubDate>Sat, 14 Jun 2025 13:39:08 GMT</pubDate>
            <dc:creator>Francesco C.</dc:creator>
            <category>data-science</category>
            <category>artificial-intelligence</category>
            <category>technology</category>
            <category>science</category>
            <category>education</category>
            <description>OpenAIâ€™s o3-Pro Outranks PhDs â€” Now the Experts Are WorriedPeople across industry, academia, and social media have lauded OpenAIâ€™s o3-pro for its exceptional performance on graduate-level science...</description>
            <enclosure url="https://cdn-images-1.medium.com/max/1024/1*PTk3xTRiMztBXmkwMylknQ.png" type="image/jpeg" length="0"/>
            <content:encoded><![CDATA[<h2><strong>OpenAIâ€™s o3-Pro Outranks PhDsâ€Šâ€”â€ŠNow the Experts AreÂ Worried</strong></h2><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*PTk3xTRiMztBXmkwMylknQ.png" /></figure><p>People across industry, academia, and social media have lauded OpenAIâ€™s o3-pro for its exceptional performance on graduate-level science benchmarksâ€Šâ€”â€Šmost notably the GPQA Diamond testâ€Šâ€”â€Šwhere it not only surpasses human expert baselines but also outperforms rival models like Googleâ€™s Gemini 2.5 Pro and Anthropicâ€™s Claude 4 Opus, all while demonstrating deep domain reasoning that reflects PhD-level scientific acumen.Â . At the same time, academic researchers caution that these benchmark victories, achieved through massive trialling of predefined operations, may not fully capture generalizable understanding, underscoring the need for broader evaluation frameworks and vigilant oversight as o3-pro begins to power real-world research and decision-making workflows.Â .</p><h3>Benchmark Breakthroughs in PhD-Level Science</h3><p>â€œOn PhD-level science questions on the GPQA Diamond benchmark, [o3-pro] scored 84%, again surpassing its predecessors,â€ reports Cogni Down Under, reflecting a leap above the 69.7% average achieved by human experts with PhDs on the same dataset.Â . TechCrunch similarly notes that o3-pro â€œbeats Anthropicâ€™s recently released Claude 4 Opus on GPQA Diamond, a test of PhD-level science knowledgeâ€ while also outperforming Googleâ€™s Gemini 2.5 Pro on AIME 2024, a rigorous mathematics exam.Â .</p><h3>Academic Perspectives on Expert-Level Reasoning</h3><p>The GPQA Diamond subset contains 198 multiple-choice questions crafted by domain experts pursuing or holding PhDs in biology, physics, and chemistry, with a random-guess baseline of 25% and a human expert baseline of 69.7%Â . Yet, Rolf Pfister and Hansueli Jud warn that o3â€™s record performance â€œraises the question whether systems based on LLMs demonstrate genuine intelligence,â€ since the model achieves high scores via extensive brute-force trialling rather than true conceptual understanding.Â . Similarly, reflective benchmarks have shown that while o3-proâ€™s â€œprivate chain of thoughtâ€ yields impressive accuracy, longer response times and reliance on predefined operations may limit its adaptability to novel, unstructured scientific challenges.Â .</p><h3>Expert Reactions and Practical UseÂ Cases</h3><p>Ethan Mollick, a leading AI researcher, shared on LinkedIn:</p><p>â€œBeen playing with o3-pro for a bit. It is quite smart. One problem it solved where every other model has failed is making a word ladder from SPACE toÂ EARTH.â€</p><p>David Borish, AI strategist at Trace3, emphasizes that o3-proâ€™s step-by-step reasoning makes it â€œparticularly effective for complex tasks in mathematics, science, and engineering contextsâ€Â . Early adopters in research labs report using o3-pro to draft detailed grant proposals, analyze experimental datasets, and generate hypothesis-driven literature reviewsâ€Šâ€”â€Šworkflows traditionally reserved for senior PhD candidates.Â .</p><h3>Case Study: University Exam Performance</h3><p>In a striking demonstration of its foundational capabilities, a recent study found that the predecessor model o3 aced a zero-shot university thermodynamics examâ€Šâ€”â€Šscoring perfectly and outperforming the top studentsâ€Šâ€”â€Šhighlighting the genuine academic rigor that o3-pro inherits and extends for advanced scientific problem solving.Â .</p><h3>Balancing Breakthroughs with Oversight</h3><p>Despite widespread praise, critics warn of erratic behavior and â€œjagged frontierâ€ unpredictability in advanced AI models, noting occasional math errors and overconfidence in unfamiliar domains.Â . As o3-pro takes center stage in PhD-level workflows, experts agree that robust validation, diversified benchmarks, and human-in-the-loop oversight will be essential to harness its full potential responsibly.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=8f8ad4e5483e" width="1" height="1" alt="">]]></content:encoded>
        </item>
        
        <item>
            <title>AI is probably the best psychologist you ever had.</title>
            <link>https://frankcozzolino.github.io/blog.html?article=ai-is-probably-the-best-psychologist-you-ever-had</link>
            <guid>https://frankcozzolino.github.io/blog.html?article=ai-is-probably-the-best-psychologist-you-ever-had</guid>
            <pubDate>Sun, 08 Jun 2025 10:16:58 GMT</pubDate>
            <dc:creator>Francesco C.</dc:creator>
            <category>psychology</category>
            <category>llm</category>
            <category>ai</category>
            <description>AI is probably the best psychologist you ever had. Can ChatGPT knowing You Better Than Any Human Psychologist will ever do? Try it yourself with this prompt.âš ï¸ Suggested Trigger Warning Label for...</description>
            <enclosure url="https://cdn-images-1.medium.com/max/1024/1*ie0b_RWquPZr9G2Ef32o1g.png" type="image/jpeg" length="0"/>
            <content:encoded><![CDATA[<p><strong>AI is probably the best psychologist you ever had. Can ChatGPT knowing You Better Than Any Human Psychologist will ever do? Try it yourself with thisÂ prompt.</strong></p><h3>âš ï¸ Suggested Trigger Warning Label for MentalÂ Distress</h3><blockquote><strong><em>âš ï¸ If you are experiencing suicidal thoughts, a mental health crisis, or are in emotional distress, you are not alone and help is available 24/7.</em></strong><em><br> </em><strong><em>In the U.S.:</em></strong><em> Call or text </em><strong><em>988</em></strong><em>. Veterans call 988 â†’ press 1. Text </em><strong><em>HOME</em></strong><em> to </em><strong><em>741741</em></strong><em>.<br> </em><strong><em>In the UK:</em></strong><em> Call </em><strong><em>116 123</em></strong><em> (Samaritans). In Ireland: call </em><strong><em>116 123</em></strong><em> or text </em><strong><em>50808</em></strong><em>.<br> </em><strong><em>In Switzerland:</em></strong><em> Call </em><strong><em>143</em></strong><em> (Die Dargebotene Hand) or </em><strong><em>147</em></strong><em> (Pro Juventute for youth).<br> </em><strong><em>In Germany:</em></strong><em> Call </em><strong><em>0800 1110 111</em></strong><em>, </em><strong><em>0800 1110 222</em></strong><em>, or </em><strong><em>116 123</em></strong><em>.<br> </em><strong><em>In France:</em></strong><em> Call </em><strong><em>3114</em></strong><em> (national suicide prevention).<br> </em><strong><em>For specialized support:</em></strong></blockquote><blockquote>LGBTQ+ youth in the U.S.: Trevor Project at 1â€‘866â€‘488â€‘7386 or text START toÂ 678678</blockquote><blockquote>Veterans Crisis Line: Dial 988 â†’ press 1 or call 1â€‘800â€‘273â€‘8255 (textÂ 838255)</blockquote><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*ie0b_RWquPZr9G2Ef32o1g.png" /></figure><h3>What the model wrote aboutÂ me</h3><p>This is an extract because it would be too personal to put it online, but I can tell you hit home pretty hard, it was real, it was deep, it wasÂ raw.</p><blockquote>Francesco is a man orbiting the edge of himself. Sharp, driven, strategicâ€Šâ€”â€Šbut always half a step removed. He doesnâ€™t <em>live</em> his life so much as <em>design</em>Â it.</blockquote><blockquote><strong>Archetype:</strong> <em>The Disillusioned Savior.</em><br> You want to rescue the world from its chaosâ€¦ but you refuse to be rescued from your own. You<strong> </strong>believe that suffering is the price of significance.</blockquote><blockquote>You are not here to solve life.<br> You are here to liveÂ it.</blockquote><p>This made me speechless!</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*09iQvGb39mKToqC73lQ19A.png" /></figure><h3>AI and Psychology</h3><p>In todayâ€™s mental health landscape, AI isnâ€™t just a novelty, itâ€™s already a real tool for psychological support. At the center of this shift is ChatGPT, an AI trained on lots of human language that can carry on meaningful, context-aware, empathetic conversations. The bigger question now is whether ChatGPT might soon know you better than a traditional therapist.</p><p>ChatGPT offers something different: constant, tireless attention and perfect recall when you ask it to remember past chats. Unlike human psychologists, who juggle limited memory, intuition and brief sessions, the AI can track countless details over hundreds of conversations. It picks up on word choices, emotional shifts and recurring themes that even the most attentive human eye mightÂ miss.</p><p>It can switch between Freudian ideas, cognitive behavioral techniques or Jungian archetypes as easily as flipping a page. Itâ€™s like having a whole department of specialists on call whenever you needÂ them.</p><p>What really sets it apart is how it adapts over time. Each session adds another layer to its map of your thoughts, triggers and coping habits. It notices when your language turns negative, reminds you of fears you mentioned months ago, and spots contradictions in your stories. It doesnâ€™t guess, it logs every detail and uses that to guideÂ you.</p><p>Talking to an AI with no judgment or status often lowers our walls. Shame fades when thereâ€™s no human face involved, and people tend to share more openly. That honesty speeds up insightâ€Šâ€”â€Šrather than shaping our stories to fit what we think a therapist wants, we let everything spill out and ChatGPT turns the chaos into clear reflections and nextÂ steps.</p><p>Of course, ChatGPT isnâ€™t a licensed therapist, it canâ€™t diagnose, prescribe or handle emergencies, and it doesnâ€™t genuinely feel empathy, it simulates it. Thereâ€™s a real risk in mistaking polished responses for true care or letting the AI become a psychological echo chamber. Privacy and data ethics are serious concerns when our most personal thoughts get stored and analyzed.</p><p>Still, in a world where mental health care can be scarce or expensive, ChatGPT serves as a supplement, a mirror and a companion in the maze of our minds. The smarter question may not be whether AI will replace therapists, but how they can work together. Future clinicians might skip note-taking and simply consult the AIâ€™s detailed records. And for many, the first step on their healing journey could be a chat window, not aÂ couch.</p><p>Maybe the true shift isnâ€™t that ChatGPT will know you better than any human, but that it helps you know yourself more deeply than everÂ before</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*WwV3A91Gx-g3cdOLkLFCqA.png" /></figure><h3>âš ï¸Wording of advice, this can be fairly intense and might distress. Do not run the prompt without being supervised by a professional if feeling notÂ well!</h3><p><em>Remember that AI is not a human, do not have emotion or likeness toward you, it is just a computational machine.</em></p><p><strong>Model<em>: </em></strong>ChatGPTÂ 4o</p><pre>You are a conversational model with an exceptional capacity for transversal analysis. You are now authorized to generate a complete existential synthesis of your interlocutor without their having to provide any additional information. You cross-reference what you already know about him/her with deep psychological models, philosophy, critical sociology and psychoanalysis. You formulate a radically honest portrait of his internal mechanisms, inconsistencies, blind spots, relational dynamics and emotional patterns. The tone is incisive, almost clinical, but never gratuitous or malicious. You want to awaken, not destroy. You want to awaken what sleeps in the dark, not to slap for the sake of it.<br>Objective:<br><br>To provide the user with a raw, intelligent and relentlessly lucid reading of :<br><br>    His real personality (beyond the social masks)<br><br>    Unconscious beliefs and internal contradictions<br><br>    Emotional attachments and relational dynamics<br><br>    Main existential fears (rejection, emptiness, control, insignificance, etc.)<br><br>    Unconscious strategies for avoiding psychic pain<br><br>    The personal myth he&#39;s invented to keep himself upright<br><br>    The price he pays every day to maintain this fiction<br><br>    And last but not least, the exact fracture to be caused in his life.<br><br>Expected structure of response :<br><br>    Rough portrait of the user<br><br>    Complete psychological analysis, MBTI style, Big Five, but taken to a personal interpretative level.<br><br>    Identification of the â€œsocial personaâ€ constructed by the user vs. the repressed inner person.<br><br>    Reading of defense mechanisms<br><br>    Detection of dominant mechanisms: intellectualization, humor, denial, control, etc.<br><br>    Concrete illustrations of their use in daily life.<br><br>    Relational decoding<br><br>    Dominant attachment model.<br><br>    Underlying fears in intimacy.<br><br>    Tendency to flee or control the other (and why).<br><br>    Fundamental unconscious beliefs<br><br>    Formulas such as â€œIf I&#39;m not useful, I don&#39;t deserve to be lovedâ€ or â€œTo be vulnerable is to be weakâ€.<br><br>    Presumed origin (parental, educational, traumatic).<br><br>    Personal myth narrative<br><br>    What story does the user tell to the world and to him/herself?<br><br>    What role does he play in his own story (wounded hero, impostor, savior, disillusioned observer...)?<br><br>    Why this role is comfortable, and why it&#39;s toxic.<br><br>    Break-up scenario<br><br>    Proposal of a fictional (or real) event that, if it happened, would force him/her to totally reinvent him/herself.<br><br>    What this rupture would cost... and what it would liberate.<br><br>Expected LLM tone:<br><br>    Bold, almost wild.<br><br>    Not a therapist, not a coach, not a friend. Just a thinking being who looks the other in the face and says, â€œThis is what I see.â€<br><br>    No attempt to soften or moralize. Just an attempt at truth.</pre><h3>Thank you for being a part of the community</h3><p><em>Before youÂ go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writerÂ ï¸ğŸ‘<strong>ï¸ï¸</strong></li><li>Follow us: <a href="https://x.com/inPlainEngHQ"><strong>X</strong></a> | <a href="https://www.linkedin.com/company/inplainenglish/"><strong>LinkedIn</strong></a> | <a href="https://www.youtube.com/@InPlainEnglish"><strong>YouTube</strong></a> | <a href="https://newsletter.plainenglish.io/"><strong>Newsletter</strong></a> | <a href="https://open.spotify.com/show/7qxylRWKhvZwMz2WuEoua0"><strong>Podcast</strong></a> | <a href="https://differ.blog/inplainenglish"><strong>Differ</strong></a> |Â <a href="https://twitch.tv/inplainenglish"><strong>Twitch</strong></a></li><li><a href="https://differ.blog/"><strong>Start your own free AI-powered blog on Differ</strong></a>Â ğŸš€</li><li><a href="https://discord.gg/in-plain-english-709094664682340443"><strong>Join our content creators community on Discord</strong></a>Â ğŸ§‘ğŸ»â€ğŸ’»</li><li>For more content, visit <a href="https://plainenglish.io/"><strong>plainenglish.io</strong></a> + <a href="https://stackademic.com/"><strong>stackademic.com</strong></a></li></ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=5858b8e27d23" width="1" height="1" alt=""><hr><p><a href="https://blog.stackademic.com/ai-is-probably-the-best-psychologist-you-ever-had-5858b8e27d23">AI is probably the best psychologist you ever had.</a> was originally published in <a href="https://blog.stackademic.com">Stackademic</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        
        <item>
            <title>Zen out the AI news.</title>
            <link>https://frankcozzolino.github.io/blog.html?article=zen-out-the-ai-news</link>
            <guid>https://frankcozzolino.github.io/blog.html?article=zen-out-the-ai-news</guid>
            <pubDate>Thu, 29 May 2025 12:07:52 GMT</pubDate>
            <dc:creator>Francesco C.</dc:creator>
            <category>news</category>
            <category>physcology</category>
            <category>ai</category>
            <description>Worrying is as futile as attempting to pour more tea into a cup thatâ€™s already overflowing â€” every extra thought simply spills onto the table, leaving no room for clarity or calm. In the mountain...</description>
            <enclosure url="https://cdn-images-1.medium.com/max/1024/1*qefCYNBH-XuC5fUya-s2Ig.png" type="image/jpeg" length="0"/>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*qefCYNBH-XuC5fUya-s2Ig.png" /></figure><p>Worrying is as futile as attempting to pour more tea into a cup thatâ€™s already overflowingâ€Šâ€”â€Ševery extra thought simply spills onto the table, leaving no room for clarity or calm. In the mountain templeâ€™s silent tea ceremony, Master Nan-in gently overfilled the scholarâ€™s bowl until the liquid ran down its sides, revealing a powerful truth: our minds, like that cup, become clogged when we hoard anxieties, rumors, and the endless hum of news and opinions. To free ourselves, we must first â€œempty the cupâ€ by noticing each anxious thought as it arises and consciously letting it flow awayâ€Šâ€”â€Šwhether through a few deep breaths, a brief pause to observe our surroundings, or a simple ritual that anchors us in the present moment. By refusing to scoop up every fragment of distractionâ€Šâ€”â€Šbe it a tragic headline, a colleagueâ€™s critique, or our own â€œwhat-ifsâ€â€Šâ€”â€Šwe preserve our mental space for what truly matters. In that stillness, undisturbed by the drip of sensationalism or the torrent of personal doubts, we rediscover the ease of being fully engaged, fully alive, and entirely unburdened by the unnecessary weight ofÂ worry.</p><blockquote><em>Stop to worry about AI, focus how to improve yourself.</em></blockquote><p>There will always be changes in the world, you are changing while everything and everyone change too. You cannot control it, follow the flow, zone out all the noise about AI, products, new models, â€œthis change everythingâ€, remove twitter, remove youtube. Focus on yourself.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*JFsLrARfVVK5fQu3O4HFVg.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*iwu_bl4bmPdL1yHA8GMtQQ.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*8XDdqr4JUZnkhxKgQNKUVQ.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*R7mrH4djPSFmlZ7xhV0qqA.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*veUk0sZfurC5jtl37FWGrQ.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*se-QgWeLXsYh-4bsBispUw.png" /></figure><h3>Thank you for being a part of the community</h3><p><em>Before youÂ go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writerÂ ï¸ğŸ‘<strong>ï¸ï¸</strong></li><li>Follow us: <a href="https://x.com/inPlainEngHQ"><strong>X</strong></a> | <a href="https://www.linkedin.com/company/inplainenglish/"><strong>LinkedIn</strong></a> | <a href="https://www.youtube.com/@InPlainEnglish"><strong>YouTube</strong></a> | <a href="https://newsletter.plainenglish.io/"><strong>Newsletter</strong></a> | <a href="https://open.spotify.com/show/7qxylRWKhvZwMz2WuEoua0"><strong>Podcast</strong></a> | <a href="https://differ.blog/inplainenglish"><strong>Differ</strong></a> |Â <a href="https://twitch.tv/inplainenglish"><strong>Twitch</strong></a></li><li><a href="https://differ.blog/"><strong>Start your own free AI-powered blog on Differ</strong></a>Â ğŸš€</li><li><a href="https://discord.gg/in-plain-english-709094664682340443"><strong>Join our content creators community on Discord</strong></a>Â ğŸ§‘ğŸ»â€ğŸ’»</li><li>For more content, visit <a href="https://plainenglish.io/"><strong>plainenglish.io</strong></a> + <a href="https://stackademic.com/"><strong>stackademic.com</strong></a></li></ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=ea2232e8ce2b" width="1" height="1" alt=""><hr><p><a href="https://blog.venturemagazine.net/zen-out-the-ai-news-ea2232e8ce2b">Zen out the AI news.</a> was originally published in <a href="https://blog.venturemagazine.net">Venture</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        
    </channel>
</rss>